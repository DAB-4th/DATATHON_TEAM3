{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 첫 번째 시도"
      ],
      "metadata": {
        "id": "0ylYDIh1kQC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 현재 데이터 구조 = 1캐릭터당 여러 장비 행\n",
        "- 1행 1캐릭터 구조로 바꾸는 것이 다소 어려워서, 머신러닝 대신 딥러닝 이용할 예정"
      ],
      "metadata": {
        "id": "HIfxOoJPS4Ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqx1fi4zFx8C"
      },
      "outputs": [],
      "source": [
        "# 'None' 문자열이 결측치로 오해받지 않도록 불러오기\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "\n",
        "# 전투력 지표 포함하고 있는 데이터 불러오기\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df와 df_stat의 '전투력' 칼럼 병합\n",
        "\n",
        "# 1. 병합 대상 컬럼만 추출 (중복 제거 포함)\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "\n",
        "# 2. left join으로 '전투력' 추가\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "\n",
        "# 3. 전투력 결측치 제거\n",
        "df.dropna(subset=['전투력'], inplace=True)"
      ],
      "metadata": {
        "id": "tgmwZ1O_GJhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AKl4-RYGM0p",
        "outputId": "4f638f05-17a1-4d57-ffd0-cc47901b3570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1059756 entries, 0 to 1063723\n",
            "Data columns (total 38 columns):\n",
            " #   Column                               Non-Null Count    Dtype  \n",
            "---  ------                               --------------    -----  \n",
            " 0   nickname                             1059756 non-null  object \n",
            " 1   subclass                             1059756 non-null  object \n",
            " 2   equipment_slot                       1059756 non-null  object \n",
            " 3   item_name                            1059756 non-null  object \n",
            " 4   boss_damage_total                    1059756 non-null  int64  \n",
            " 5   ignore_monster_armor_total           1059756 non-null  int64  \n",
            " 6   all_stat_total                       1059756 non-null  int64  \n",
            " 7   damage_total                         1059756 non-null  int64  \n",
            " 8   potential_option_grade               1059756 non-null  object \n",
            " 9   additional_potential_option_grade    1059756 non-null  object \n",
            " 10  exceptional_upgrade                  1059756 non-null  bool   \n",
            " 11  boss_damage_add                      1059756 non-null  int64  \n",
            " 12  damage_add                           1059756 non-null  int64  \n",
            " 13  all_stat_add                         1059756 non-null  int64  \n",
            " 14  starforce                            1059756 non-null  int64  \n",
            " 15  starforce_scroll_flag                1059756 non-null  object \n",
            " 16  special_ring_level                   1059756 non-null  int64  \n",
            " 17  main_stat_type                       1059756 non-null  object \n",
            " 18  bonus_stat_total                     1059756 non-null  int64  \n",
            " 19  mainstat_total                       1059756 non-null  float64\n",
            " 20  power_total                          1059756 non-null  float64\n",
            " 21  potential_option_1_grade             1059756 non-null  object \n",
            " 22  potential_option_2_grade             1059756 non-null  object \n",
            " 23  potential_option_3_grade             1059756 non-null  object \n",
            " 24  main_pot_grade_summary               1059756 non-null  object \n",
            " 25  additional_potential_option_1_grade  1059756 non-null  object \n",
            " 26  additional_potential_option_2_grade  1059756 non-null  object \n",
            " 27  additional_potential_option_3_grade  1059756 non-null  object \n",
            " 28  add_pot_grade_summary                1059756 non-null  object \n",
            " 29  mainstat_add                         1059756 non-null  float64\n",
            " 30  power_add                            1059756 non-null  float64\n",
            " 31  mainstat_etc                         1059756 non-null  float64\n",
            " 32  power_etc                            1059756 non-null  int64  \n",
            " 33  mainstat_starforce                   1059756 non-null  float64\n",
            " 34  power_starforce                      1059756 non-null  int64  \n",
            " 35  potential_status                     1059756 non-null  object \n",
            " 36  item_group                           1059756 non-null  object \n",
            " 37  전투력                                  1059756 non-null  float64\n",
            "dtypes: bool(1), float64(7), int64(12), object(18)\n",
            "memory usage: 308.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import torch\n",
        "\n",
        "# 전처리 구성\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# Label encoding\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col, encoder in encoders.items():\n",
        "    df[col] = encoder.transform(df[col])\n",
        "\n",
        "# 수치형 정규화\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "N4VQueJeVOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 장비 시퀀스 만들기\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24  # 최대 장비 수\n",
        "\n",
        "character_inputs = []\n",
        "character_labels = []\n",
        "attention_masks = []  # 마스크 추가\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    features = group[feature_cols].values\n",
        "    valid_len = len(features)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad = np.zeros((max_len - valid_len, feature_dim))\n",
        "        features = np.vstack([features, pad])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        features = features[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    character_inputs.append(torch.tensor(features, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['전투력'].iloc[0])"
      ],
      "metadata": {
        "id": "i2LA1gSKVN9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor 변환\n",
        "X = torch.stack(character_inputs)          # (B, T, D)\n",
        "mask = torch.stack(attention_masks)        # (B, T)\n",
        "y = torch.tensor(character_labels)         # (B,)"
      ],
      "metadata": {
        "id": "_9sGYc06VN4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "import torch.nn as nn\n",
        "\n",
        "class DeepSetMasked(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):  # x: (B, T, D), mask: (B, T)\n",
        "        encoded = self.phi(x)  # (B, T, H)\n",
        "        masked_encoded = encoded * mask.unsqueeze(-1)  # mask 확장 후 곱하기\n",
        "        aggregated = masked_encoded.sum(dim=1)  # (B, H)\n",
        "        return self.rho(aggregated).squeeze()  # (B,)"
      ],
      "metadata": {
        "id": "VMlwb-BTVNw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 만들기\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(X, mask, y)\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "dmvB1_PJVNqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "model = DeepSetMasked(input_dim=X.shape[-1]).to(\"cuda\")\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for xb, mb, yb in train_loader:\n",
        "        xb = xb.to(\"cuda\")\n",
        "        mb = mb.to(\"cuda\")\n",
        "        yb = yb.to(\"cuda\").float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * len(xb)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss / len(dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGCir_2dbBBN",
        "outputId": "c37e9658-1365-4172-fb67-5e62a1db8983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 20313777141531684.0000\n",
            "Epoch 2 - Loss: 10104777078699980.0000\n",
            "Epoch 3 - Loss: 9557737416839084.0000\n",
            "Epoch 4 - Loss: 8866219926050771.0000\n",
            "Epoch 5 - Loss: 7874012985708706.0000\n",
            "Epoch 6 - Loss: 6750520516183836.0000\n",
            "Epoch 7 - Loss: 6049198103661723.0000\n",
            "Epoch 8 - Loss: 5757279609114496.0000\n",
            "Epoch 9 - Loss: 5630692330944702.0000\n",
            "Epoch 10 - Loss: 5557885620930596.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X.to(\"cuda\"), mask.to(\"cuda\")).cpu().numpy()\n",
        "    y_true = y.cpu().numpy()"
      ],
      "metadata": {
        "id": "U3YecKmLbA8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "mse = mean_squared_error(y_true, preds)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw4qM8G5bA5K",
        "outputId": "4bc0142e-4e00-40da-f88d-9819b3b7738f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 74,356,325\n",
            "R²: 0.4940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 두 번째 시도"
      ],
      "metadata": {
        "id": "ljjWGfd4j-Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'None' 문자열이 결측치로 오해받지 않도록 불러오기\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "\n",
        "# 전투력 지표 포함하고 있는 데이터 불러오기\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')"
      ],
      "metadata": {
        "id": "4vagse7ckLPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df와 df_stat의 '전투력' 칼럼 병합\n",
        "\n",
        "# 1. 병합 대상 컬럼만 추출 (중복 제거 포함)\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "\n",
        "# 2. left join으로 '전투력' 추가\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "\n",
        "# 3. 전투력 결측치 제거\n",
        "df.dropna(subset=['전투력'], inplace=True)"
      ],
      "metadata": {
        "id": "1gtBCom0kTZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 대상 열\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# 결측치 처리 (간단히 dropna)\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "\n",
        "# 범주형 인코딩\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# 수치형 정규화\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# log 변환\n",
        "df['log_전투력'] = np.log1p(df['전투력'])"
      ],
      "metadata": {
        "id": "kxzmsGa9bA2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn\n",
        "\n",
        "# === 1. 전처리 구성 ===\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "existing_cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "existing_num_cols = [col for col in num_cols if col in df.columns]\n",
        "target_col = '전투력'\n",
        "\n",
        "df = df.dropna(subset=existing_cat_cols + existing_num_cols + [target_col])\n",
        "\n",
        "# 인코딩 + 정규화\n",
        "for col in existing_cat_cols:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[existing_num_cols] = scaler.fit_transform(df[existing_num_cols])\n",
        "\n",
        "df['log_전투력'] = np.log1p(df[target_col])\n",
        "\n",
        "# === 2. 데이터 준비 ===\n",
        "X = torch.tensor(df[existing_cat_cols + existing_num_cols].values, dtype=torch.float32)\n",
        "y = torch.tensor(df['log_전투력'].values, dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# === 3. 모델 정의 ===\n",
        "class SimpleRegressor(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n",
        "\n",
        "model = SimpleRegressor(X.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# === 4. 학습 ===\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# === 5. 평가 ===\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X).numpy()\n",
        "    y_true = y.numpy()\n",
        "    y_pred_exp = np.expm1(y_pred)\n",
        "    y_true_exp = np.expm1(y_true)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true_exp, y_pred_exp))\n",
        "r2 = r2_score(y_true_exp, y_pred_exp)\n",
        "\n",
        "print(f\"📊 최종 평가 결과\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rsU4Yb-bA0n",
        "outputId": "b0140033-e448-4e2a-ee46-1dd42aaa251a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1.3431\n",
            "Epoch 2: Loss = 0.9169\n",
            "Epoch 3: Loss = 0.9009\n",
            "Epoch 4: Loss = 0.8930\n",
            "Epoch 5: Loss = 0.8864\n",
            "Epoch 6: Loss = 0.8815\n",
            "Epoch 7: Loss = 0.8775\n",
            "Epoch 8: Loss = 0.8762\n",
            "Epoch 9: Loss = 0.8728\n",
            "Epoch 10: Loss = 0.8708\n",
            "📊 최종 평가 결과\n",
            "RMSE: 89,449,549\n",
            "R²: 0.2594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 세 번째 시도"
      ],
      "metadata": {
        "id": "Tcf6yBLvnUzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked DeepSets로 시퀀스 학습\n",
        "\n",
        "# (1) 데이터 전처리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 사용할 범주형 / 수치형 컬럼 정의\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# 존재하는 열만 필터링\n",
        "cat_cols = [col for col in cat_cols if col in df.columns]\n",
        "num_cols = [col for col in num_cols if col in df.columns]\n",
        "\n",
        "# 전투력 유효성 확인\n",
        "if '전투력' not in df.columns:\n",
        "    raise ValueError(\"❌ '전투력' 컬럼이 존재하지 않습니다.\")\n",
        "\n",
        "# 결측치 제거\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "\n",
        "# 범주형 인코딩\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# 수치형 정규화\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# 전투력 로그 변환 (추후 선택적으로 사용 가능)\n",
        "df['log_전투력'] = np.log1p(df['전투력'])"
      ],
      "metadata": {
        "id": "DafeZ4yEbAvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) 캐릭터별 장비 시퀀스 구성(nickname 기준 groupby)\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24  # 캐릭터당 최대 장비 수\n",
        "\n",
        "character_inputs = []\n",
        "character_labels = []\n",
        "attention_masks = []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    features = group[feature_cols].values\n",
        "    valid_len = len(features)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad = np.zeros((max_len - valid_len, feature_dim))\n",
        "        features = np.vstack([features, pad])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        features = features[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    character_inputs.append(torch.tensor(features, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['전투력'].iloc[0])  # log_전투력으로 바꿀 수도 있음\n",
        "\n",
        "X = torch.stack(character_inputs).float()                # (B, T, D)\n",
        "mask = torch.stack(attention_masks).float()              # (B, T)\n",
        "y = torch.tensor(character_labels, dtype=torch.float32)  # (B,)"
      ],
      "metadata": {
        "id": "iz8Gz2d3bAtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) Masked DeepSets 모델 정의\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSets(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # x: (B, T, D), mask: (B, T)\n",
        "        encoded = self.phi(x)                          # (B, T, 64)\n",
        "        masked = encoded * mask.unsqueeze(-1)          # (B, T, 64)\n",
        "        pooled = masked.sum(dim=1)                     # (B, 64)\n",
        "        return self.rho(pooled).squeeze()              # (B,)"
      ],
      "metadata": {
        "id": "Sd4noVWgbAq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# 데이터셋 및 로더 구성\n",
        "dataset = TensorDataset(X, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 모델 초기화\n",
        "model = MaskedDeepSets(input_dim=X.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 학습\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X, mask).numpy()\n",
        "    y_true = y.numpy()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"\\n📊 최종 평가 결과:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHVCrn-6bAkY",
        "outputId": "00c7cfdc-5522-41a2-885a-e97d4b8e8d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 21320032586292988.0000\n",
            "Epoch 2: Loss = 10198710239161158.0000\n",
            "Epoch 3: Loss = 9711300646582294.0000\n",
            "Epoch 4: Loss = 9142901835325022.0000\n",
            "Epoch 5: Loss = 8357941116880978.0000\n",
            "Epoch 6: Loss = 7326946706100004.0000\n",
            "Epoch 7: Loss = 6429572304124114.0000\n",
            "Epoch 8: Loss = 5940441267996914.0000\n",
            "Epoch 9: Loss = 5726394045816610.0000\n",
            "Epoch 10: Loss = 5622332282307216.0000\n",
            "\n",
            "📊 최종 평가 결과:\n",
            "RMSE: 74,712,527\n",
            "R²: 0.4891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 튜닝 시도 (1)\n",
        "# 범주형 Feature -> Embedding vector로 표현\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSetsWithEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        # x_cat: (B, T, num_cat), x_cont: (B, T, num_cont), mask: (B, T)\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)  # (B, T, total_emb_dim)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)  # (B, T, input_dim)\n",
        "\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()"
      ],
      "metadata": {
        "id": "H7RSziSIqh9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding 모델 학습을 위한 입력 분리 및 텐서 생성\n",
        "\n",
        "# 1. embedding 정보 구성 (각 범주형 컬럼의 고유값 개수)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 2. feature 분리\n",
        "feature_cols = cat_cols + num_cols\n",
        "feature_dim = len(feature_cols)\n",
        "max_len = 24\n",
        "\n",
        "x_cat_list = []\n",
        "x_cont_list = []\n",
        "attention_masks = []\n",
        "character_labels = []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    cat_feats = group[cat_cols].values.astype(np.int64)  # long 타입으로 변환\n",
        "    cont_feats = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)), dtype=np.int64)\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)), dtype=np.float32)\n",
        "        cat_feats = np.vstack([cat_feats, pad_cat])\n",
        "        cont_feats = np.vstack([cont_feats, pad_cont])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        cat_feats = cat_feats[:max_len]\n",
        "        cont_feats = cont_feats[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat_feats, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont_feats, dtype=torch.float32))\n",
        "    attention_masks.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    character_labels.append(group['전투력'].iloc[0])  # log_전투력으로 바꿔도 됨\n",
        "\n",
        "# 텐서화\n",
        "x_cat = torch.stack(x_cat_list)       # (B, T, num_cat)\n",
        "x_cont = torch.stack(x_cont_list)     # (B, T, num_cont)\n",
        "mask = torch.stack(attention_masks)   # (B, T)\n",
        "y = torch.tensor(character_labels, dtype=torch.float32)  # (B,)\n",
        "\n",
        "# 확인\n",
        "x_cat.shape, x_cont.shape, mask.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnUm6VVXq1A9",
        "outputId": "ec539c0d-b1da-4365-844c-5721827ee205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([45770, 24, 10]),\n",
              " torch.Size([45770, 24, 18]),\n",
              " torch.Size([45770, 24]),\n",
              " torch.Size([45770]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding 모델 학습 루프 + 평가 코드\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 데이터셋 및 DataLoader 생성\n",
        "dataset = TensorDataset(x_cat, x_cont, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 모델 초기화\n",
        "model = MaskedDeepSetsWithEmbedding(embedding_info, num_cont_features=x_cont.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 학습\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xcb, xfb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")\n",
        "\n",
        "# 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(x_cat, x_cont, mask).numpy()\n",
        "    y_true = y.numpy()\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_true, preds))\n",
        "r2 = r2_score(y_true, preds)\n",
        "\n",
        "print(f\"\\n📊 최종 평가 결과:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlMN4oFLrsrs",
        "outputId": "320466c8-384b-4b26-9e75-82fd3c349d00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 19354970680136156.0000\n",
            "Epoch 2: Loss = 6985824516823240.0000\n",
            "Epoch 3: Loss = 5738621470542747.0000\n",
            "Epoch 4: Loss = 5513033042183031.0000\n",
            "Epoch 5: Loss = 5432516061833051.0000\n",
            "Epoch 6: Loss = 5383590933385174.0000\n",
            "Epoch 7: Loss = 5341979742175306.0000\n",
            "Epoch 8: Loss = 5311223582819306.0000\n",
            "Epoch 9: Loss = 5291353764650500.0000\n",
            "Epoch 10: Loss = 5272607709977308.0000\n",
            "\n",
            "📊 최종 평가 결과:\n",
            "RMSE: 72,540,977\n",
            "R²: 0.5184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 네 번째 시도"
      ],
      "metadata": {
        "id": "D5pbME5wu2mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# 전처리 구성\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "# log 전투력으로 바꾸기\n",
        "df['log_전투력'] = np.log1p(df['전투력'])"
      ],
      "metadata": {
        "id": "KfjZDipEsPSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시퀀스 구성\n",
        "import torch\n",
        "\n",
        "max_len = 24\n",
        "feature_dim = len(cat_cols + num_cols)\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby('nickname'):\n",
        "    cat_feats = group[cat_cols].values.astype(np.int64)\n",
        "    cont_feats = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        cat_feats = np.vstack([cat_feats, np.zeros((max_len - valid_len, len(cat_cols)))])\n",
        "        cont_feats = np.vstack([cont_feats, np.zeros((max_len - valid_len, len(num_cols)))])\n",
        "        mask = [1] * valid_len + [0] * (max_len - valid_len)\n",
        "    else:\n",
        "        cat_feats = cat_feats[:max_len]\n",
        "        cont_feats = cont_feats[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat_feats, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont_feats, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))  # log 전투력\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "s2-6NogQvBy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "import torch.nn as nn\n",
        "\n",
        "class MaskedDeepSetsWithEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Softplus()  # log 예측 폭주 방지\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()"
      ],
      "metadata": {
        "id": "OVkCM9mGvHK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(x_cat, x_cont, mask, y)\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = MaskedDeepSetsWithEmbedding(embedding_info, x_cont.shape[-1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xcb, xfb, mb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(xcb, xfb, mb)\n",
        "        loss = criterion(pred, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9qQ3D3qvY6R",
        "outputId": "8833442c-64c1-4740-abb1-6a431e38a41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 5.7401\n",
            "Epoch 2: Loss = 0.7835\n",
            "Epoch 3: Loss = 0.6542\n",
            "Epoch 4: Loss = 0.6242\n",
            "Epoch 5: Loss = 0.6122\n",
            "Epoch 6: Loss = 0.5977\n",
            "Epoch 7: Loss = 0.5904\n",
            "Epoch 8: Loss = 0.5796\n",
            "Epoch 9: Loss = 0.5688\n",
            "Epoch 10: Loss = 0.5471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_log = model(x_cat, x_cont, mask).numpy()\n",
        "    y_log = y.numpy()\n",
        "\n",
        "# 안정성: 클리핑\n",
        "pred_log = np.clip(pred_log, 0, 50)\n",
        "y_log = np.clip(y_log, 0, 50)\n",
        "\n",
        "# 전투력 복원\n",
        "pred_real = np.expm1(pred_log)\n",
        "y_real = np.expm1(y_log)\n",
        "\n",
        "# 지표\n",
        "rmse = np.sqrt(mean_squared_error(y_real, pred_real))\n",
        "rmsle = np.sqrt(mean_squared_error(np.log1p(y_real), np.log1p(pred_real)))\n",
        "r2 = r2_score(y_real, pred_real)\n",
        "\n",
        "print(f\"📊 평가 결과:\")\n",
        "print(f\"RMSE: {rmse:,.0f}\")\n",
        "print(f\"RMSLE: {rmsle:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx4DLMDovcst",
        "outputId": "1b5e4b92-a67b-49a6-8dbb-f797cf3afd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 평가 결과:\n",
            "RMSE: 73,975,112\n",
            "RMSLE: 0.7019\n",
            "R²: 0.4992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다섯 번째 시도"
      ],
      "metadata": {
        "id": "qDiG3M6bxKuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 시드 고정\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. 정렬 보장된 groupby → 텐서 구성\n",
        "df = df.sort_values(\"nickname\")  # 필수 정렬\n",
        "\n",
        "# 장비 수 파생 피처\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "# 3. 딥러닝 모델 정의\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # Softplus 제거: 전투력 직접 예측\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 4. K-Fold 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fold별 평가\n",
        "    model.eval()\n",
        "    preds_all, y_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for xcb, xfb, mb, yb in val_loader:\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            preds_all.append(preds.numpy())\n",
        "            y_all.append(yb.numpy())\n",
        "\n",
        "    pred_all = np.concatenate(preds_all)\n",
        "    y_true = np.concatenate(y_all)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred_all))\n",
        "    r2 = r2_score(y_true, pred_all)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "    print(f\"✅ Fold {fold+1} RMSE: {rmse:,.2f}, R²: {r2:.4f}\")\n",
        "\n",
        "# 최종 평균 출력\n",
        "print(\"\\n🎯 K-Fold 평균 성능:\")\n",
        "print(f\"Avg RMSE: {np.mean(rmses):,.2f}\")\n",
        "print(f\"Avg R²: {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBF8lY20xGMQ",
        "outputId": "54cf9eaa-fcc9-4f00-f95d-f58c73325104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 3.4886\n",
            "Epoch 2: Loss = 0.7343\n",
            "Epoch 3: Loss = 0.6853\n",
            "Epoch 4: Loss = 0.6459\n",
            "Epoch 5: Loss = 0.6000\n",
            "Epoch 6: Loss = 0.5665\n",
            "Epoch 7: Loss = 0.5513\n",
            "Epoch 8: Loss = 0.5325\n",
            "Epoch 9: Loss = 0.5008\n",
            "Epoch 10: Loss = 0.4938\n",
            "✅ Fold 1 RMSE: 0.73, R²: 0.6740\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 4.0717\n",
            "Epoch 2: Loss = 0.7298\n",
            "Epoch 3: Loss = 0.6257\n",
            "Epoch 4: Loss = 0.5967\n",
            "Epoch 5: Loss = 0.5543\n",
            "Epoch 6: Loss = 0.5527\n",
            "Epoch 7: Loss = 0.5215\n",
            "Epoch 8: Loss = 0.5127\n",
            "Epoch 9: Loss = 0.4905\n",
            "Epoch 10: Loss = 0.4871\n",
            "✅ Fold 2 RMSE: 0.71, R²: 0.6544\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 4.6613\n",
            "Epoch 2: Loss = 0.6714\n",
            "Epoch 3: Loss = 0.6011\n",
            "Epoch 4: Loss = 0.5780\n",
            "Epoch 5: Loss = 0.5465\n",
            "Epoch 6: Loss = 0.5278\n",
            "Epoch 7: Loss = 0.5015\n",
            "Epoch 8: Loss = 0.4608\n",
            "Epoch 9: Loss = 0.4540\n",
            "Epoch 10: Loss = 0.4435\n",
            "✅ Fold 3 RMSE: 1.00, R²: 0.4164\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 4.8802\n",
            "Epoch 2: Loss = 0.7252\n",
            "Epoch 3: Loss = 0.6534\n",
            "Epoch 4: Loss = 0.6133\n",
            "Epoch 5: Loss = 0.5635\n",
            "Epoch 6: Loss = 0.5344\n",
            "Epoch 7: Loss = 0.5197\n",
            "Epoch 8: Loss = 0.5025\n",
            "Epoch 9: Loss = 0.4899\n",
            "Epoch 10: Loss = 0.4668\n",
            "✅ Fold 4 RMSE: 0.81, R²: 0.6442\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 4.9042\n",
            "Epoch 2: Loss = 0.6916\n",
            "Epoch 3: Loss = 0.6190\n",
            "Epoch 4: Loss = 0.5996\n",
            "Epoch 5: Loss = 0.5719\n",
            "Epoch 6: Loss = 0.5604\n",
            "Epoch 7: Loss = 0.5315\n",
            "Epoch 8: Loss = 0.5102\n",
            "Epoch 9: Loss = 0.5027\n",
            "Epoch 10: Loss = 0.4902\n",
            "✅ Fold 5 RMSE: 0.70, R²: 0.7282\n",
            "\n",
            "🎯 K-Fold 평균 성능:\n",
            "Avg RMSE: 0.79\n",
            "Avg R²: 0.6235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE -> HuberLoss로 바꾸고 다시 실행\n",
        "\n",
        "# 1. 시드 고정\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. 정렬 보장된 groupby → 텐서 구성\n",
        "df = df.sort_values(\"nickname\")  # 필수 정렬\n",
        "\n",
        "# 장비 수 파생 피처\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "# 3. 딥러닝 모델 정의\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)  # Softplus 제거: 전투력 직접 예측\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 4. K-Fold 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.HuberLoss(delta=1.0)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fold별 평가\n",
        "    model.eval()\n",
        "    preds_all, y_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for xcb, xfb, mb, yb in val_loader:\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            preds_all.append(preds.numpy())\n",
        "            y_all.append(yb.numpy())\n",
        "\n",
        "    pred_all = np.concatenate(preds_all)\n",
        "    y_true = np.concatenate(y_all)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred_all))\n",
        "    r2 = r2_score(y_true, pred_all)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "    print(f\"✅ Fold {fold+1} RMSE: {rmse:,.2f}, R²: {r2:.4f}\")\n",
        "\n",
        "# 최종 평균 출력\n",
        "print(\"\\n🎯 K-Fold 평균 성능:\")\n",
        "print(f\"Avg RMSE: {np.mean(rmses):,.2f}\")\n",
        "print(f\"Avg R²: {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3lXbQXB7jhC",
        "outputId": "7770b830-c455-46b1-bcea-7946cd96b97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 0.4246\n",
            "Epoch 2: Loss = 0.1550\n",
            "Epoch 3: Loss = 0.1408\n",
            "Epoch 4: Loss = 0.1360\n",
            "Epoch 5: Loss = 0.1363\n",
            "Epoch 6: Loss = 0.1286\n",
            "Epoch 7: Loss = 0.1292\n",
            "Epoch 8: Loss = 0.1271\n",
            "Epoch 9: Loss = 0.1229\n",
            "Epoch 10: Loss = 0.1238\n",
            "✅ Fold 1 RMSE: 0.77, R²: 0.6381\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 0.4636\n",
            "Epoch 2: Loss = 0.1583\n",
            "Epoch 3: Loss = 0.1492\n",
            "Epoch 4: Loss = 0.1358\n",
            "Epoch 5: Loss = 0.1315\n",
            "Epoch 6: Loss = 0.1290\n",
            "Epoch 7: Loss = 0.1218\n",
            "Epoch 8: Loss = 0.1197\n",
            "Epoch 9: Loss = 0.1187\n",
            "Epoch 10: Loss = 0.1171\n",
            "✅ Fold 2 RMSE: 0.76, R²: 0.6004\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 0.4842\n",
            "Epoch 2: Loss = 0.1509\n",
            "Epoch 3: Loss = 0.1406\n",
            "Epoch 4: Loss = 0.1307\n",
            "Epoch 5: Loss = 0.1260\n",
            "Epoch 6: Loss = 0.1266\n",
            "Epoch 7: Loss = 0.1258\n",
            "Epoch 8: Loss = 0.1241\n",
            "Epoch 9: Loss = 0.1102\n",
            "Epoch 10: Loss = 0.1194\n",
            "✅ Fold 3 RMSE: 0.97, R²: 0.4501\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 0.4939\n",
            "Epoch 2: Loss = 0.1481\n",
            "Epoch 3: Loss = 0.1389\n",
            "Epoch 4: Loss = 0.1369\n",
            "Epoch 5: Loss = 0.1300\n",
            "Epoch 6: Loss = 0.1256\n",
            "Epoch 7: Loss = 0.1261\n",
            "Epoch 8: Loss = 0.1222\n",
            "Epoch 9: Loss = 0.1181\n",
            "Epoch 10: Loss = 0.1185\n",
            "✅ Fold 4 RMSE: 0.86, R²: 0.5968\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 0.4897\n",
            "Epoch 2: Loss = 0.1566\n",
            "Epoch 3: Loss = 0.1433\n",
            "Epoch 4: Loss = 0.1303\n",
            "Epoch 5: Loss = 0.1328\n",
            "Epoch 6: Loss = 0.1216\n",
            "Epoch 7: Loss = 0.1226\n",
            "Epoch 8: Loss = 0.1149\n",
            "Epoch 9: Loss = 0.1214\n",
            "Epoch 10: Loss = 0.1138\n",
            "✅ Fold 5 RMSE: 0.78, R²: 0.6547\n",
            "\n",
            "🎯 K-Fold 평균 성능:\n",
            "Avg RMSE: 0.83\n",
            "Avg R²: 0.5880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: 오차 큰 캐릭터만 추출하여 fine-tune용 텐서 구성\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "    y_all = y.numpy()\n",
        "\n",
        "# 상위 10% 오차 유저를 대상\n",
        "abs_errors = np.abs(pred_all - y_all)\n",
        "threshold = np.percentile(abs_errors, 90)  # 상위 10%\n",
        "error_indices = np.where(abs_errors > threshold)[0]\n",
        "print(f\"🎯 상위 10% 오차 캐릭터 수: {len(error_indices)}\")\n",
        "\n",
        "# 해당 인덱스의 텐서만 추출\n",
        "x_cat_ft = x_cat[error_indices]\n",
        "x_cont_ft = x_cont_with_count[error_indices]\n",
        "mask_ft = mask[error_indices]\n",
        "y_ft = y[error_indices]\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "ft_dataset = TensorDataset(x_cat_ft, x_cont_ft, mask_ft, y_ft)\n",
        "ft_loader = DataLoader(ft_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 2: 기존 모델 그대로 불러와 fine-tune (3 epoch)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for xcb, xfb, mb, yb in ft_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "# Step 3: 전체 RMSE 다시 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "print(f\"\\n📊 Fine-tune 이후 전체 평가:\")\n",
        "print(f\"RMSE: {final_rmse:,.2f}\")\n",
        "print(f\"R²: {final_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSUuqZZK7jeg",
        "outputId": "f9891c33-c58f-4b00-fa05-28b68c1652dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 상위 10% 오차 캐릭터 수: 4577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Fine-tune Epoch 1: Loss = 4.3509\n",
            "🔧 Fine-tune Epoch 2: Loss = 4.0787\n",
            "🔧 Fine-tune Epoch 3: Loss = 3.8983\n",
            "\n",
            "📊 Fine-tune 이후 전체 평가:\n",
            "RMSE: 0.76\n",
            "R²: 0.6604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: 오차 큰 캐릭터만 추출하여 fine-tune용 텐서 구성\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "    y_all = y.numpy()\n",
        "\n",
        "# 상위 30% 오차 유저를 대상\n",
        "abs_errors = np.abs(pred_all - y_all)\n",
        "threshold = np.percentile(abs_errors, 70)  # 상위 30% 커트라인\n",
        "error_indices = np.where(abs_errors > threshold)[0]\n",
        "print(f\"🎯 상위 30% 오차 캐릭터 수: {len(error_indices)}\")\n",
        "\n",
        "# 해당 인덱스의 텐서만 추출\n",
        "x_cat_ft = x_cat[error_indices]\n",
        "x_cont_ft = x_cont_with_count[error_indices]\n",
        "mask_ft = mask[error_indices]\n",
        "y_ft = y[error_indices]\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "ft_dataset = TensorDataset(x_cat_ft, x_cont_ft, mask_ft, y_ft)\n",
        "ft_loader = DataLoader(ft_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Step 2: 기존 모델 그대로 불러와 fine-tune (3 epoch)\n",
        "model.train()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    total_loss = 0\n",
        "    for xcb, xfb, mb, yb in ft_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xcb, xfb, mb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * len(xcb)\n",
        "    print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "# Step 3: 전체 RMSE 다시 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "print(f\"\\n📊 Fine-tune 이후 전체 평가:\")\n",
        "print(f\"RMSE: {final_rmse:,.2f}\")\n",
        "print(f\"R²: {final_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfxXyTI_-vDP",
        "outputId": "035498be-b1d1-4d44-cfdb-b09f606e62e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 상위 30% 오차 캐릭터 수: 13731\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.4933\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.4428\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.4206\n",
            "\n",
            "📊 Fine-tune 이후 전체 평가:\n",
            "RMSE: 0.71\n",
            "R²: 0.7001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# 모델 저장 경로 설정\n",
        "save_path = \"best_model_r2_0700_rmse_071.pt\"\n",
        "\n",
        "# 모델 state_dict 저장\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"✅ 모델이 저장되었습니다: {save_path}\")\n",
        "\n",
        "# 성능 요약표 정리\n",
        "results = pd.DataFrame([\n",
        "    {\"모델\": \"기본 DeepSets\", \"RMSE\": 0.79, \"R²\": 0.6235},\n",
        "    {\"모델\": \"DeepSets + HuberLoss\", \"RMSE\": 0.83, \"R²\": 0.5880},\n",
        "    {\"모델\": \"DeepSets + Fine-Tune (10%)\", \"RMSE\": 0.76, \"R²\": 0.6604},\n",
        "    {\"모델\": \"DeepSets + Fine-Tune (30%)\", \"RMSE\": 0.71, \"R²\": 0.7001},\n",
        "    {\"모델\": \"Attention 구조\", \"RMSE\": 0.76, \"R²\": 0.6547},\n",
        "    {\"모델\": \"Attention 구조 + 잘못된 fine-tune\", \"RMSE\": 1.12, \"R²\": 0.2606},\n",
        "])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "iBahcfJr7jas",
        "outputId": "ae3fe719-f95c-4df1-f034-d0b753b5f9f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델이 저장되었습니다: best_model_r2_0700_rmse_071.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             모델  RMSE      R²\n",
              "0                   기본 DeepSets  0.79  0.6235\n",
              "1          DeepSets + HuberLoss  0.83  0.5880\n",
              "2    DeepSets + Fine-Tune (10%)  0.76  0.6604\n",
              "3    DeepSets + Fine-Tune (30%)  0.71  0.7001\n",
              "4                  Attention 구조  0.76  0.6547\n",
              "5  Attention 구조 + 잘못된 fine-tune  1.12  0.2606"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>모델</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R²</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>기본 DeepSets</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.6235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DeepSets + HuberLoss</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.5880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DeepSets + Fine-Tune (10%)</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.6604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DeepSets + Fine-Tune (30%)</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.7001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Attention 구조</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.6547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Attention 구조 + 잘못된 fine-tune</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.2606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d38a0490-8b86-4ab3-b9c2-0cb23729ce86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-336ccb65-2200-43dd-a0be-69f679ea8d8a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-336ccb65-2200-43dd-a0be-69f679ea8d8a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-336ccb65-2200-43dd-a0be-69f679ea8d8a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0e37f8c4-2a6d-418e-aade-e310b6ddcb80\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0e37f8c4-2a6d-418e-aade-e310b6ddcb80 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\ubaa8\\ub378\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\uae30\\ubcf8 DeepSets\",\n          \"DeepSets + HuberLoss\",\n          \"Attention \\uad6c\\uc870 + \\uc798\\ubabb\\ub41c fine-tune\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RMSE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1482452922242952,\n        \"min\": 0.71,\n        \"max\": 1.12,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.83,\n          1.12,\n          0.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\\u00b2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16151284056280685,\n        \"min\": 0.2606,\n        \"max\": 0.7001,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.6235,\n          0.588,\n          0.2606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"best_model_r2_0700_rmse_071.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kujWA7NTJrRJ",
        "outputId": "f01a3c77-3584-453e-afab-1ff6b89ed8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab8df380-73fe-4e14-9541-2a3f40f583e0\", \"best_model_r2_0700_rmse_071.pt\", 439294)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 불러올 모델 클래스 정의\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 모델 인스턴스 생성 후 .pt 파일 불러오기\n",
        "model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "\n",
        "# 모델 가중치 로드\n",
        "model.load_state_dict(torch.load(\"best_model_r2_0700_rmse_071.pt\"))\n",
        "\n",
        "# 예측용 모드로 전환\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "DQ1PCHEVJrOj",
        "outputId": "bc06d9e2-85e5-4c7c-c2d8-19e06b503e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for DeepMaskedModel:\n\tUnexpected key(s) in state_dict: \"attention_score.weight\", \"attention_score.bias\", \"rho.4.weight\", \"rho.4.bias\". \n\tsize mismatch for embeddings.subclass.weight: copying a param with shape torch.Size([46, 16]) from checkpoint, the shape in current model is torch.Size([46, 8]).\n\tsize mismatch for embeddings.equipment_slot.weight: copying a param with shape torch.Size([24, 16]) from checkpoint, the shape in current model is torch.Size([24, 8]).\n\tsize mismatch for embeddings.main_stat_type.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.item_group.weight: copying a param with shape torch.Size([15, 16]) from checkpoint, the shape in current model is torch.Size([15, 8]).\n\tsize mismatch for embeddings.starforce_scroll_flag.weight: copying a param with shape torch.Size([2, 16]) from checkpoint, the shape in current model is torch.Size([2, 8]).\n\tsize mismatch for embeddings.potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.additional_potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.main_pot_grade_summary.weight: copying a param with shape torch.Size([42, 16]) from checkpoint, the shape in current model is torch.Size([42, 8]).\n\tsize mismatch for embeddings.add_pot_grade_summary.weight: copying a param with shape torch.Size([55, 16]) from checkpoint, the shape in current model is torch.Size([55, 8]).\n\tsize mismatch for embeddings.potential_status.weight: copying a param with shape torch.Size([27, 16]) from checkpoint, the shape in current model is torch.Size([27, 8]).\n\tsize mismatch for phi.0.weight: copying a param with shape torch.Size([256, 179]) from checkpoint, the shape in current model is torch.Size([256, 99]).\n\tsize mismatch for rho.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for rho.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for rho.2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for rho.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([1]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-155116b9c2f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# 모델 가중치 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model_r2_0700_rmse_071.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# 예측용 모드로 전환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DeepMaskedModel:\n\tUnexpected key(s) in state_dict: \"attention_score.weight\", \"attention_score.bias\", \"rho.4.weight\", \"rho.4.bias\". \n\tsize mismatch for embeddings.subclass.weight: copying a param with shape torch.Size([46, 16]) from checkpoint, the shape in current model is torch.Size([46, 8]).\n\tsize mismatch for embeddings.equipment_slot.weight: copying a param with shape torch.Size([24, 16]) from checkpoint, the shape in current model is torch.Size([24, 8]).\n\tsize mismatch for embeddings.main_stat_type.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.item_group.weight: copying a param with shape torch.Size([15, 16]) from checkpoint, the shape in current model is torch.Size([15, 8]).\n\tsize mismatch for embeddings.starforce_scroll_flag.weight: copying a param with shape torch.Size([2, 16]) from checkpoint, the shape in current model is torch.Size([2, 8]).\n\tsize mismatch for embeddings.potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.additional_potential_option_grade.weight: copying a param with shape torch.Size([6, 16]) from checkpoint, the shape in current model is torch.Size([6, 8]).\n\tsize mismatch for embeddings.main_pot_grade_summary.weight: copying a param with shape torch.Size([42, 16]) from checkpoint, the shape in current model is torch.Size([42, 8]).\n\tsize mismatch for embeddings.add_pot_grade_summary.weight: copying a param with shape torch.Size([55, 16]) from checkpoint, the shape in current model is torch.Size([55, 8]).\n\tsize mismatch for embeddings.potential_status.weight: copying a param with shape torch.Size([27, 16]) from checkpoint, the shape in current model is torch.Size([27, 8]).\n\tsize mismatch for phi.0.weight: copying a param with shape torch.Size([256, 179]) from checkpoint, the shape in current model is torch.Size([256, 99]).\n\tsize mismatch for rho.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([32, 64]).\n\tsize mismatch for rho.0.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for rho.2.weight: copying a param with shape torch.Size([64, 128]) from checkpoint, the shape in current model is torch.Size([1, 32]).\n\tsize mismatch for rho.2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([1])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 불러올 모델 클래스 정의\n",
        "class AttentionMaskedModelV2(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=16, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.attention_score = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        h = self.phi(x)\n",
        "        attn_scores = self.attention_score(h).squeeze(-1)\n",
        "        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attn_weights = F.softmax(attn_scores, dim=1).unsqueeze(-1)\n",
        "        weighted_sum = torch.sum(h * self.dropout(attn_weights), dim=1)\n",
        "        return self.rho(weighted_sum).squeeze()"
      ],
      "metadata": {
        "id": "HywiqU1IJrKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 시 embedding_info, 연속형 피처 차원 수 일치시키기\n",
        "model = AttentionMaskedModelV2(embedding_info, x_cont_with_count.shape[-1])\n",
        "\n",
        "# 가중치 불러오기\n",
        "model.load_state_dict(torch.load(\"best_model_r2_0700_rmse_071.pt\"))\n",
        "\n",
        "# 평가 모드 전환\n",
        "model.eval()\n",
        "print(\"모델 로딩 성공\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb3ELcFv7jTM",
        "outputId": "8599855c-6c08-4b29-b95a-42f524b1c49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 로딩 성공\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가장 성능 좋았던 모델 저장하기"
      ],
      "metadata": {
        "id": "iFa_w8VGq5Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "rN888wbzwjkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 시드 설정\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. 데이터 불러오기 및 병합\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# 3. 전처리\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])  # 로그 변환\n",
        "\n",
        "# 4. 시퀀스 구성\n",
        "df = df.sort_values(\"nickname\")\n",
        "max_len = 24\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list) # 총 24개의 슬롯 중 몇 개 안 낀 애가 있다면 없는 장비에 대해서는 무시\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 5. 모델 정의\n",
        "class DeepMaskedModel(nn.Module): # Deepsets\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 6. K-Fold + Fine-tune\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # 상위 30% 오차 캐릭터만 Fine-tune\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices],\n",
        "        x_cont_with_count[error_indices],\n",
        "        mask[error_indices],\n",
        "        y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "    print(f\"✅ Fold {fold+1} Final RMSE: {final_rmse:,.2f}, R²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# 최종 성능 출력\n",
        "print(f\"\\n🎯 평균 성능: RMSE = {np.mean(rmses):,.2f}, R² = {np.mean(r2s):.4f}\")\n",
        "\n",
        "# 모델 저장\n",
        "torch.save(model.state_dict(), f\"best_model_r2_{np.mean(r2s):.4f}_rmse_{np.mean(rmses):.2f}.pt\")\n",
        "print(\"✅ 모델 저장 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43hv7AIZ0BY6",
        "outputId": "942453ae-d0b6-46e0-c665-8d107550f5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 3.4882\n",
            "Epoch 2: Loss = 0.7373\n",
            "Epoch 3: Loss = 0.6872\n",
            "Epoch 4: Loss = 0.6495\n",
            "Epoch 5: Loss = 0.6062\n",
            "Epoch 6: Loss = 0.5705\n",
            "Epoch 7: Loss = 0.5539\n",
            "Epoch 8: Loss = 0.5349\n",
            "Epoch 9: Loss = 0.5038\n",
            "Epoch 10: Loss = 0.5001\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2077\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1489\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1188\n",
            "✅ Fold 1 Final RMSE: 0.67, R²: 0.7328\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 3.4654\n",
            "Epoch 2: Loss = 0.7116\n",
            "Epoch 3: Loss = 0.6481\n",
            "Epoch 4: Loss = 0.6123\n",
            "Epoch 5: Loss = 0.5787\n",
            "Epoch 6: Loss = 0.5548\n",
            "Epoch 7: Loss = 0.5422\n",
            "Epoch 8: Loss = 0.5196\n",
            "Epoch 9: Loss = 0.4873\n",
            "Epoch 10: Loss = 0.4991\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.1377\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.0677\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.0406\n",
            "✅ Fold 2 Final RMSE: 0.72, R²: 0.6951\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 4.4264\n",
            "Epoch 2: Loss = 0.6740\n",
            "Epoch 3: Loss = 0.6047\n",
            "Epoch 4: Loss = 0.5652\n",
            "Epoch 5: Loss = 0.5611\n",
            "Epoch 6: Loss = 0.5318\n",
            "Epoch 7: Loss = 0.5050\n",
            "Epoch 8: Loss = 0.5109\n",
            "Epoch 9: Loss = 0.4738\n",
            "Epoch 10: Loss = 0.4611\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.0123\n",
            "🔧 Fine-tune Epoch 2: Loss = 0.9737\n",
            "🔧 Fine-tune Epoch 3: Loss = 0.9490\n",
            "✅ Fold 3 Final RMSE: 0.69, R²: 0.7164\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 4.2300\n",
            "Epoch 2: Loss = 0.6981\n",
            "Epoch 3: Loss = 0.6211\n",
            "Epoch 4: Loss = 0.5966\n",
            "Epoch 5: Loss = 0.5804\n",
            "Epoch 6: Loss = 0.5514\n",
            "Epoch 7: Loss = 0.5355\n",
            "Epoch 8: Loss = 0.5072\n",
            "Epoch 9: Loss = 0.5129\n",
            "Epoch 10: Loss = 0.4872\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2825\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.2302\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1989\n",
            "✅ Fold 4 Final RMSE: 0.76, R²: 0.6542\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 3.5911\n",
            "Epoch 2: Loss = 0.7226\n",
            "Epoch 3: Loss = 0.6645\n",
            "Epoch 4: Loss = 0.6251\n",
            "Epoch 5: Loss = 0.5922\n",
            "Epoch 6: Loss = 0.5834\n",
            "Epoch 7: Loss = 0.5447\n",
            "Epoch 8: Loss = 0.5446\n",
            "Epoch 9: Loss = 0.4935\n",
            "Epoch 10: Loss = 0.4953\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2455\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1639\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1187\n",
            "✅ Fold 5 Final RMSE: 0.66, R²: 0.7432\n",
            "\n",
            "🎯 평균 성능: RMSE = 0.70, R² = 0.7083\n",
            "✅ 모델 저장 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 사용하기"
      ],
      "metadata": {
        "id": "3lRcPxNfrhwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 현재 상황: 딥러닝 기반 전투력 예측기는 꽤나 잘 만들어짐\n",
        "- 현재 문제점: 근데 이걸 사용하려면 뉴비 유저 입장에서 아이템 24개의 정보를 세세하게 다 입력해야(입력값 투머치) 정확하게 전투력를 예측받을 수 있음"
      ],
      "metadata": {
        "id": "FRfoE3dklgrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용할 모델 다시 불러오기\n",
        "# 1. 시드 설정\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 2. 데이터 불러오기 및 병합\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# 3. 전처리\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])  # 로그 변환\n",
        "\n",
        "# 4. 시퀀스 구성\n",
        "df = df.sort_values(\"nickname\")\n",
        "max_len = 24\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list) # 총 24개의 슬롯 중 몇 개 안 낀 애가 있다면 없는 장비에 대해서는 무시\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 5. 모델 정의\n",
        "class DeepMaskedModel(nn.Module): # Deepsets\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        emb_cat = torch.cat(embs, dim=-1)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 6. K-Fold + Fine-tune\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # 상위 30% 오차 캐릭터만 Fine-tune\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices],\n",
        "        x_cont_with_count[error_indices],\n",
        "        mask[error_indices],\n",
        "        y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb, xfb, mb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat, x_cont_with_count, mask).numpy()\n",
        "\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "\n",
        "    print(f\"✅ Fold {fold+1} Final RMSE: {final_rmse:,.2f}, R²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# 최종 성능 출력\n",
        "print(f\"\\n🎯 평균 성능: RMSE = {np.mean(rmses):,.2f}, R² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YN5lKHpUiFQi",
        "outputId": "42da58b3-7c03-46f6-a649-35072df4db4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 3.4882\n",
            "Epoch 2: Loss = 0.7373\n",
            "Epoch 3: Loss = 0.6872\n",
            "Epoch 4: Loss = 0.6495\n",
            "Epoch 5: Loss = 0.6062\n",
            "Epoch 6: Loss = 0.5705\n",
            "Epoch 7: Loss = 0.5539\n",
            "Epoch 8: Loss = 0.5349\n",
            "Epoch 9: Loss = 0.5038\n",
            "Epoch 10: Loss = 0.5001\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2077\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1489\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1188\n",
            "✅ Fold 1 Final RMSE: 0.67, R²: 0.7328\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 3.4654\n",
            "Epoch 2: Loss = 0.7116\n",
            "Epoch 3: Loss = 0.6481\n",
            "Epoch 4: Loss = 0.6123\n",
            "Epoch 5: Loss = 0.5787\n",
            "Epoch 6: Loss = 0.5548\n",
            "Epoch 7: Loss = 0.5422\n",
            "Epoch 8: Loss = 0.5196\n",
            "Epoch 9: Loss = 0.4873\n",
            "Epoch 10: Loss = 0.4991\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.1377\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.0677\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.0406\n",
            "✅ Fold 2 Final RMSE: 0.72, R²: 0.6951\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 4.4264\n",
            "Epoch 2: Loss = 0.6740\n",
            "Epoch 3: Loss = 0.6047\n",
            "Epoch 4: Loss = 0.5652\n",
            "Epoch 5: Loss = 0.5611\n",
            "Epoch 6: Loss = 0.5318\n",
            "Epoch 7: Loss = 0.5050\n",
            "Epoch 8: Loss = 0.5109\n",
            "Epoch 9: Loss = 0.4738\n",
            "Epoch 10: Loss = 0.4611\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.0123\n",
            "🔧 Fine-tune Epoch 2: Loss = 0.9737\n",
            "🔧 Fine-tune Epoch 3: Loss = 0.9490\n",
            "✅ Fold 3 Final RMSE: 0.69, R²: 0.7164\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 4.2300\n",
            "Epoch 2: Loss = 0.6981\n",
            "Epoch 3: Loss = 0.6211\n",
            "Epoch 4: Loss = 0.5966\n",
            "Epoch 5: Loss = 0.5804\n",
            "Epoch 6: Loss = 0.5514\n",
            "Epoch 7: Loss = 0.5355\n",
            "Epoch 8: Loss = 0.5072\n",
            "Epoch 9: Loss = 0.5129\n",
            "Epoch 10: Loss = 0.4872\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2825\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.2302\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1989\n",
            "✅ Fold 4 Final RMSE: 0.76, R²: 0.6542\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 3.5911\n",
            "Epoch 2: Loss = 0.7226\n",
            "Epoch 3: Loss = 0.6645\n",
            "Epoch 4: Loss = 0.6251\n",
            "Epoch 5: Loss = 0.5922\n",
            "Epoch 6: Loss = 0.5834\n",
            "Epoch 7: Loss = 0.5447\n",
            "Epoch 8: Loss = 0.5446\n",
            "Epoch 9: Loss = 0.4935\n",
            "Epoch 10: Loss = 0.4953\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.2455\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1639\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1187\n",
            "✅ Fold 5 Final RMSE: 0.66, R²: 0.7432\n",
            "\n",
            "🎯 평균 성능: RMSE = 0.70, R² = 0.7083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중요도가 높은 장비 부위 확인"
      ],
      "metadata": {
        "id": "QA4zl01lmwEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_slot_importance(model, x_cat, x_cont, mask, y, cat_cols, equipment_slot_col, device='cpu'):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    # 장비 슬롯 컬럼 인덱스\n",
        "    slot_idx = cat_cols.index(equipment_slot_col)\n",
        "\n",
        "    # 기본 예측값\n",
        "    with torch.no_grad():\n",
        "        base_pred = model(x_cat.to(device), x_cont.to(device), mask.to(device)).cpu().numpy()\n",
        "    y_true = y.numpy()\n",
        "    base_rmse = np.sqrt(((y_true - base_pred) ** 2).mean())\n",
        "\n",
        "    # 고유 슬롯 추출\n",
        "    unique_slots = torch.unique(x_cat[:, :, slot_idx]).tolist()\n",
        "    slot_importance = {}\n",
        "\n",
        "    for slot in tqdm(unique_slots, desc=\"📊 장비 중요도 분석 중\"):\n",
        "        # perturb할 위치 마스크\n",
        "        slot_mask = (x_cat[:, :, slot_idx] == slot)\n",
        "\n",
        "        # x_cat 복제\n",
        "        x_cat_perturbed = x_cat.clone()\n",
        "\n",
        "        # 해당 위치만 랜덤값으로 대체 (해당 칼럼만 따로 작업)\n",
        "        max_val = x_cat[:, :, slot_idx].max().item() + 1\n",
        "        rand_vals = torch.randint(0, max_val, slot_mask.shape)\n",
        "        x_cat_perturbed[:, :, slot_idx][slot_mask] = rand_vals[slot_mask]\n",
        "\n",
        "        # 예측\n",
        "        with torch.no_grad():\n",
        "            pred = model(x_cat_perturbed.to(device), x_cont.to(device), mask.to(device)).cpu().numpy()\n",
        "\n",
        "        # RMSE 변화량 저장\n",
        "        perturbed_rmse = np.sqrt(((y_true - pred) ** 2).mean())\n",
        "        delta = perturbed_rmse - base_rmse\n",
        "        slot_importance[slot] = delta\n",
        "\n",
        "    return sorted(slot_importance.items(), key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "r9HTYjgTj4SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 장비 부위 중요도 계산\n",
        "slot_scores = compute_slot_importance(\n",
        "    model=model,\n",
        "    x_cat=x_cat,\n",
        "    x_cont=x_cont_with_count,\n",
        "    mask=mask,\n",
        "    y=y,\n",
        "    cat_cols=cat_cols,\n",
        "    equipment_slot_col='equipment_slot'\n",
        ")\n",
        "\n",
        "# equipment_slot 인코더로 디코딩\n",
        "equipment_slot_encoder = encoders['equipment_slot']\n",
        "decoded_scores = [(equipment_slot_encoder.inverse_transform([slot])[0], delta) for slot, delta in slot_scores]\n",
        "\n",
        "# 상위 Top-N 출력\n",
        "top_n = 10\n",
        "for i, (slot_name, delta) in enumerate(decoded_scores[:top_n]):\n",
        "    print(f\"{i+1}. {slot_name} ➜ 전투력 예측 RMSE 변화량: {delta:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeTwB6T5j4Pu",
        "outputId": "be5de42b-ca03-4847-c233-756a9a7f9607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📊 장비 중요도 분석 중: 100%|██████████| 24/24 [00:40<00:00,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 무기 ➜ 전투력 예측 RMSE 변화량: 5.0923\n",
            "2. 뱃지 ➜ 전투력 예측 RMSE 변화량: 0.2533\n",
            "3. 모자 ➜ 전투력 예측 RMSE 변화량: 0.1940\n",
            "4. 훈장 ➜ 전투력 예측 RMSE 변화량: 0.1739\n",
            "5. 하의 ➜ 전투력 예측 RMSE 변화량: 0.1460\n",
            "6. 신발 ➜ 전투력 예측 RMSE 변화량: 0.1455\n",
            "7. 장갑 ➜ 전투력 예측 RMSE 변화량: 0.1450\n",
            "8. 망토 ➜ 전투력 예측 RMSE 변화량: 0.1434\n",
            "9. 어깨장식 ➜ 전투력 예측 RMSE 변화량: 0.1300\n",
            "10. 포켓 아이템 ➜ 전투력 예측 RMSE 변화량: 0.1274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중요도 Top 3 (무기, 뱃지, 모자) 만 사용한 경량 모델 구축 및 실험"
      ],
      "metadata": {
        "id": "rzYSYMw5nC6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 설정\n",
        "top_slots = ['무기', '뱃지', '모자']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# Top-3 장비만 필터링\n",
        "df = df[df['equipment_slot'].isin(top_slots)].copy()\n",
        "\n",
        "# 전처리\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])\n",
        "\n",
        "# 시퀀스 구성\n",
        "max_len = 3  # 장비 개수 (무기, 뱃지, 모자)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "-Hn0BU-ej4M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 모델 정의 (기존 구조 그대로 재사용)\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def _embed(self, x_cat):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        return torch.cat(embs, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        emb_cat = self._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 5-Fold 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1]).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fine-tune: 예측 오차 상위 30%\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices], x_cont_with_count[error_indices], mask[error_indices], y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "    print(f\"✅ Fold {fold+1} Final RMSE: {final_rmse:,.2f}, R²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# 최종 성능\n",
        "print(f\"\\n Top-3 장비 기반 평균 성능: RMSE = {np.mean(rmses):,.2f}, R² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nSW13mErj4Js",
        "outputId": "c02d4598-6c0e-4e06-c155-29606b626ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 10.3448\n",
            "Epoch 2: Loss = 0.5981\n",
            "Epoch 3: Loss = 0.5621\n",
            "Epoch 4: Loss = 0.5551\n",
            "Epoch 5: Loss = 0.5630\n",
            "Epoch 6: Loss = 0.5667\n",
            "Epoch 7: Loss = 0.5554\n",
            "Epoch 8: Loss = 0.5606\n",
            "Epoch 9: Loss = 0.5485\n",
            "Epoch 10: Loss = 0.5381\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3257\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.2987\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.2880\n",
            "✅ Fold 1 Final RMSE: 0.86, R²: 0.5394\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 8.7736\n",
            "Epoch 2: Loss = 0.6277\n",
            "Epoch 3: Loss = 0.5846\n",
            "Epoch 4: Loss = 0.5818\n",
            "Epoch 5: Loss = 0.5789\n",
            "Epoch 6: Loss = 0.5630\n",
            "Epoch 7: Loss = 0.5674\n",
            "Epoch 8: Loss = 0.5500\n",
            "Epoch 9: Loss = 0.5501\n",
            "Epoch 10: Loss = 0.5539\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3338\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.3002\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.2948\n",
            "✅ Fold 2 Final RMSE: 0.79, R²: 0.6108\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 8.3407\n",
            "Epoch 2: Loss = 0.6105\n",
            "Epoch 3: Loss = 0.5752\n",
            "Epoch 4: Loss = 0.5794\n",
            "Epoch 5: Loss = 0.5650\n",
            "Epoch 6: Loss = 0.5713\n",
            "Epoch 7: Loss = 0.5651\n",
            "Epoch 8: Loss = 0.5648\n",
            "Epoch 9: Loss = 0.5433\n",
            "Epoch 10: Loss = 0.5420\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3728\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.3455\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.3268\n",
            "✅ Fold 3 Final RMSE: 0.81, R²: 0.5874\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 10.2369\n",
            "Epoch 2: Loss = 0.6033\n",
            "Epoch 3: Loss = 0.5690\n",
            "Epoch 4: Loss = 0.5675\n",
            "Epoch 5: Loss = 0.5516\n",
            "Epoch 6: Loss = 0.5662\n",
            "Epoch 7: Loss = 0.5597\n",
            "Epoch 8: Loss = 0.5551\n",
            "Epoch 9: Loss = 0.5423\n",
            "Epoch 10: Loss = 0.5425\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3869\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.3696\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.3571\n",
            "✅ Fold 4 Final RMSE: 0.78, R²: 0.6159\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 9.1725\n",
            "Epoch 2: Loss = 0.6389\n",
            "Epoch 3: Loss = 0.6039\n",
            "Epoch 4: Loss = 0.6019\n",
            "Epoch 5: Loss = 0.5982\n",
            "Epoch 6: Loss = 0.5841\n",
            "Epoch 7: Loss = 0.5951\n",
            "Epoch 8: Loss = 0.5903\n",
            "Epoch 9: Loss = 0.5902\n",
            "Epoch 10: Loss = 0.5685\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.1847\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1628\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1564\n",
            "✅ Fold 5 Final RMSE: 0.85, R²: 0.5468\n",
            "\n",
            " Top-3 장비 기반 평균 성능: RMSE = 0.82, R² = 0.5801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 중요도 Top 5 (무기, 뱃지, 모자, 훈장, 장갑) 만 사용한 경량 모델 구축 및 실험"
      ],
      "metadata": {
        "id": "zaGyFFLZXOkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 설정\n",
        "top_5_slots = ['무기', '뱃지', '모자', '훈장', '장갑']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# Top-5 장비만 필터링\n",
        "df = df[df['equipment_slot'].isin(top_5_slots)].copy()\n",
        "\n",
        "# 전처리\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])\n",
        "\n",
        "# 시퀀스 구성\n",
        "max_len = 5  # 장비 개수\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont_with_count = torch.cat([x_cont, equip_counts], dim=2)\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}"
      ],
      "metadata": {
        "id": "gLupb9Voj4Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 모델 정의 (기존 구조 그대로 재사용)\n",
        "class DeepMaskedModel(nn.Module):\n",
        "    def __init__(self, embedding_info, num_cont_features, emb_dim=8):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            col: nn.Embedding(num_classes, emb_dim)\n",
        "            for col, num_classes in embedding_info.items()\n",
        "        })\n",
        "        self.total_emb_dim = len(embedding_info) * emb_dim\n",
        "        self.input_dim = self.total_emb_dim + num_cont_features\n",
        "\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def _embed(self, x_cat):\n",
        "        embs = [self.embeddings[col](x_cat[..., i]) for i, col in enumerate(self.embeddings)]\n",
        "        return torch.cat(embs, dim=-1)\n",
        "\n",
        "    def forward(self, x_cat, x_cont, mask):\n",
        "        emb_cat = self._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = self.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "        return self.rho(pooled).squeeze()\n",
        "\n",
        "# 5-Fold 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    print(f\"\\n📂 Fold {fold + 1}\")\n",
        "\n",
        "    train_set = TensorDataset(x_cat[train_idx], x_cont_with_count[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = TensorDataset(x_cat[val_idx], x_cont_with_count[val_idx], mask[val_idx], y[val_idx])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=256, shuffle=False)\n",
        "\n",
        "    model = DeepMaskedModel(embedding_info, x_cont_with_count.shape[-1]).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader.dataset):.4f}\")\n",
        "\n",
        "    # Fine-tune: 예측 오차 상위 30%\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_all = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "        y_all = y.numpy()\n",
        "    abs_errors = np.abs(pred_all - y_all)\n",
        "    threshold = np.percentile(abs_errors, 70)\n",
        "    error_indices = np.where(abs_errors > threshold)[0]\n",
        "\n",
        "    ft_set = TensorDataset(\n",
        "        x_cat[error_indices], x_cont_with_count[error_indices], mask[error_indices], y[error_indices]\n",
        "    )\n",
        "    ft_loader = DataLoader(ft_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    for epoch in range(3):\n",
        "        total_loss = 0\n",
        "        for xcb, xfb, mb, yb in ft_loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xcb.to(device), xfb.to(device), mb.to(device))\n",
        "            loss = criterion(preds, yb.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(xcb)\n",
        "        print(f\"🔧 Fine-tune Epoch {epoch+1}: Loss = {total_loss / len(ft_loader.dataset):.4f}\")\n",
        "\n",
        "    # 평가\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        final_pred = model(x_cat.to(device), x_cont_with_count.to(device), mask.to(device)).cpu().numpy()\n",
        "    final_rmse = np.sqrt(mean_squared_error(y_all, final_pred))\n",
        "    final_r2 = r2_score(y_all, final_pred)\n",
        "    print(f\"✅ Fold {fold+1} Final RMSE: {final_rmse:,.2f}, R²: {final_r2:.4f}\")\n",
        "    rmses.append(final_rmse)\n",
        "    r2s.append(final_r2)\n",
        "\n",
        "# 최종 성능\n",
        "print(f\"\\n Top-5 장비 기반 평균 성능: RMSE = {np.mean(rmses):,.2f}, R² = {np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kva4Rn0bj4D8",
        "outputId": "722d136c-4069-441a-ef41-72e85c21f268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1\n",
            "Epoch 1: Loss = 8.2146\n",
            "Epoch 2: Loss = 0.7032\n",
            "Epoch 3: Loss = 0.5847\n",
            "Epoch 4: Loss = 0.5602\n",
            "Epoch 5: Loss = 0.5450\n",
            "Epoch 6: Loss = 0.5460\n",
            "Epoch 7: Loss = 0.5583\n",
            "Epoch 8: Loss = 0.5517\n",
            "Epoch 9: Loss = 0.5293\n",
            "Epoch 10: Loss = 0.5296\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3020\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.2799\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.2626\n",
            "✅ Fold 1 Final RMSE: 0.75, R²: 0.6493\n",
            "\n",
            "📂 Fold 2\n",
            "Epoch 1: Loss = 8.4987\n",
            "Epoch 2: Loss = 0.6026\n",
            "Epoch 3: Loss = 0.5527\n",
            "Epoch 4: Loss = 0.5299\n",
            "Epoch 5: Loss = 0.5319\n",
            "Epoch 6: Loss = 0.5229\n",
            "Epoch 7: Loss = 0.5277\n",
            "Epoch 8: Loss = 0.5118\n",
            "Epoch 9: Loss = 0.4880\n",
            "Epoch 10: Loss = 0.5087\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.3041\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.2635\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.2449\n",
            "✅ Fold 2 Final RMSE: 0.70, R²: 0.6969\n",
            "\n",
            "📂 Fold 3\n",
            "Epoch 1: Loss = 7.2001\n",
            "Epoch 2: Loss = 0.6577\n",
            "Epoch 3: Loss = 0.5735\n",
            "Epoch 4: Loss = 0.5499\n",
            "Epoch 5: Loss = 0.5594\n",
            "Epoch 6: Loss = 0.5455\n",
            "Epoch 7: Loss = 0.5395\n",
            "Epoch 8: Loss = 0.5342\n",
            "Epoch 9: Loss = 0.5315\n",
            "Epoch 10: Loss = 0.5072\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.1451\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.1300\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.1112\n",
            "✅ Fold 3 Final RMSE: 0.79, R²: 0.6109\n",
            "\n",
            "📂 Fold 4\n",
            "Epoch 1: Loss = 9.3789\n",
            "Epoch 2: Loss = 0.6701\n",
            "Epoch 3: Loss = 0.5905\n",
            "Epoch 4: Loss = 0.5754\n",
            "Epoch 5: Loss = 0.5646\n",
            "Epoch 6: Loss = 0.5620\n",
            "Epoch 7: Loss = 0.5501\n",
            "Epoch 8: Loss = 0.5589\n",
            "Epoch 9: Loss = 0.5438\n",
            "Epoch 10: Loss = 0.5388\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.4358\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.3927\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.3830\n",
            "✅ Fold 4 Final RMSE: 0.71, R²: 0.6870\n",
            "\n",
            "📂 Fold 5\n",
            "Epoch 1: Loss = 9.0001\n",
            "Epoch 2: Loss = 0.6621\n",
            "Epoch 3: Loss = 0.5742\n",
            "Epoch 4: Loss = 0.5612\n",
            "Epoch 5: Loss = 0.5476\n",
            "Epoch 6: Loss = 0.5512\n",
            "Epoch 7: Loss = 0.5518\n",
            "Epoch 8: Loss = 0.5488\n",
            "Epoch 9: Loss = 0.5320\n",
            "Epoch 10: Loss = 0.5235\n",
            "🔧 Fine-tune Epoch 1: Loss = 1.4255\n",
            "🔧 Fine-tune Epoch 2: Loss = 1.3990\n",
            "🔧 Fine-tune Epoch 3: Loss = 1.3848\n",
            "✅ Fold 5 Final RMSE: 0.71, R²: 0.6916\n",
            "\n",
            " Top-5 장비 기반 평균 성능: RMSE = 0.73, R² = 0.6671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 코사인 유사도 기반 유사 유저 추천"
      ],
      "metadata": {
        "id": "KEiZKRz4r6vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# phi(x) 벡터 추출 함수 정의\n",
        "def extract_user_vector(model, x_cat, x_cont, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        emb_cat = model._embed(x_cat)\n",
        "        x = torch.cat([emb_cat, x_cont], dim=-1)\n",
        "        encoded = model.phi(x)\n",
        "        masked = encoded * mask.unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "    return pooled.cpu().numpy()"
      ],
      "metadata": {
        "id": "KubMXvv5j38d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 고레벨 유저 벡터 생성 & 저장\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# 고레벨 유저 기준: 전투력 상위 30% 등\n",
        "high_power_idx = np.argsort(-y.numpy())[:int(len(y) * 0.3)]\n",
        "\n",
        "# 벡터 생성\n",
        "model.eval()\n",
        "hl_vecs = []\n",
        "hl_nicks = []\n",
        "\n",
        "for i in high_power_idx:\n",
        "    vec = extract_user_vector(\n",
        "        model,\n",
        "        x_cat[i:i+1].to(device),\n",
        "        x_cont_with_count[i:i+1].to(device),\n",
        "        mask[i:i+1].to(device)\n",
        "    )[0]\n",
        "    hl_vecs.append(vec)\n",
        "    hl_nicks.append(df[df['nickname'] == df['nickname'].unique()[i]]['nickname'].iloc[0])\n",
        "\n",
        "hl_vecs = np.stack(hl_vecs)\n",
        "hl_nicks = np.array(hl_nicks)\n",
        "\n",
        "# 저장\n",
        "np.save(\"high_level_user_vectors.npy\", hl_vecs)\n",
        "np.save(\"high_level_user_nicks.npy\", hl_nicks)"
      ],
      "metadata": {
        "id": "0LpkxIO1pufM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 직업 기반 평균값 사전 구축 -> 유저가 정보를 입력하지 않는 경우에도 자동으로 채워줄 수 있게끔\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# 모든 인코딩 컬럼 디코딩 (범주형)\n",
        "df_decoded = df.copy()\n",
        "for col in cat_cols:\n",
        "    if col in encoders:\n",
        "        df_decoded[col] = encoders[col].inverse_transform(df[col])\n",
        "\n",
        "# 사전 구조 초기화\n",
        "subclass_profiles = defaultdict(lambda: defaultdict(dict))\n",
        "top_slots = ['무기', '모자', '장갑'] # 훈장과 뱃지 아이템의 경우, 유저들의 별도 강화가 불가능한 부위기 때문에 제외\n",
        "\n",
        "# 사전 구축\n",
        "for subclass in df_decoded['subclass'].unique():\n",
        "    for slot in top_slots:\n",
        "        # 해당 직업-부위 데이터 필터링\n",
        "        filtered = df_decoded[\n",
        "            (df_decoded['subclass'] == subclass) &\n",
        "            (df_decoded['equipment_slot'] == slot)\n",
        "        ]\n",
        "        if filtered.empty:\n",
        "            continue\n",
        "\n",
        "        # 범주형: 최빈값 저장 (디코딩된 상태)\n",
        "        for col in cat_cols:\n",
        "            try:\n",
        "                mode_val = filtered[col].mode(dropna=True)\n",
        "                if not mode_val.empty:\n",
        "                    subclass_profiles[subclass][slot][col] = mode_val.iloc[0]\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # 수치형: 정규화된 평균값 → 원래 스케일로 역변환 후 저장\n",
        "        for col in num_cols:\n",
        "            try:\n",
        "                mean_val = filtered[col].mean()\n",
        "                if np.isnan(mean_val):\n",
        "                    continue\n",
        "                col_index = num_cols.index(col)\n",
        "                dummy_vec = np.zeros(len(num_cols))\n",
        "                dummy_vec[col_index] = mean_val\n",
        "                original_val = scaler.inverse_transform([dummy_vec])[0][col_index]\n",
        "                subclass_profiles[subclass][slot][col] = round(original_val, 2)\n",
        "            except:\n",
        "                continue"
      ],
      "metadata": {
        "id": "3YBF9S-i8AGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 예시: 나이트로드 유저가 장갑 정보 입력 안 했을 때\n",
        "slot_profile = subclass_profiles['나이트로드']['장갑']\n",
        "\n",
        "print(\"🔹 주스탯 유형:\", slot_profile.get('main_stat_type', 'N/A'))\n",
        "print(\"🔹 스타포스 평균:\", slot_profile.get('starforce', 'N/A'))\n",
        "print(\"🔹 장비 세트:\", slot_profile.get('item_group', 'N/A'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tP3-EbbA8ACz",
        "outputId": "75b89d85-e0ae-4547-d4f1-d70643b79d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 주스탯 유형: LUK\n",
            "🔹 스타포스 평균: 20.8\n",
            "🔹 장비 세트: 아케인셰이드\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 직업 기반 평균값 -> 저장 코드\n",
        "import pickle\n",
        "\n",
        "with open(\"subclass_profiles.pkl\", \"wb\") as f:\n",
        "    pickle.dump(dict(subclass_profiles), f)  # defaultdict는 dict로 변환해서 저장"
      ],
      "metadata": {
        "id": "HQMwCaHxCdkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 직업 기반 평균값 -> 불러오기 코드\n",
        "with open(\"subclass_profiles.pkl\", \"rb\") as f:\n",
        "    subclass_profiles = pickle.load(f)"
      ],
      "metadata": {
        "id": "acPa5VI2CdfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = {\n",
        "    'subclass': '카인',\n",
        "    '무기': {\n",
        "        'item_group': '도전자',       # 장비 세트\n",
        "        'starforce': 15,              # 스타포스 강화 수치\n",
        "        'mainstat_total': 124,        # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 80,            # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 12,         # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '유니크',            # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': 'B',               # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'B',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': '기타', # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': '기타'  # 에디셔널 잠재옵션 3의 분류\n",
        "},\n",
        "    '모자': {\n",
        "        'item_group': '파프니르',       # 장비 세트\n",
        "        'starforce': 20,                # 스타포스 강화 수치\n",
        "        'mainstat_total': 300,          # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 78,              # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 6,            # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '레전드리',          # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': 'S',               # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'B',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': '기타', # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': 'B'     # 에디셔널 잠재옵션 3의 분류\n",
        "},\n",
        "    '장갑': {\n",
        "        'item_group': '앱솔랩스',       # 장비 세트\n",
        "        'starforce': 18,                # 스타포스 강화 수치\n",
        "        'mainstat_total': 100,          # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 70,              # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 0,            # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '유니크',            # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': '기타',            # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'S',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': 'S',    # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': '기타'  # 에디셔널 잠재옵션 3의 분류\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "bsOEUKI6CdcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중요도 높은 아이템 정보 입력 기반 유사 유저 추천\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 직업별 주스탯 매핑\n",
        "main_stat_map = {\n",
        "    \"STR\": [\"히어로\", \"아델\", \"소울마스터\", \"아란\", \"제로\", \"팔라딘\", \"다크나이트\", \"카이저\",\n",
        "            \"데몬슬레이어\", \"미하일\", \"블래스터\", \"은월\", \"바이퍼\", \"스트라이커\", \"캐논마스터\", \"아크\"],\n",
        "    \"DEX\": [\"윈드브레이커\", \"메르세데스\", \"보우마스터\", \"패스파인더\", \"신궁\", \"카인\", \"와일드헌터\",\n",
        "            \"엔젤릭버스터\", \"캡틴\", \"메카닉\"],\n",
        "    \"INT\": [\"비숍\", \"아크메이지(불,독)\", \"아크메이지(썬,콜)\", \"라라\", \"배틀메이지\", \"에반\", \"루미너스\",\n",
        "            \"키네시스\", \"플레임위자드\", \"일리움\"],\n",
        "    \"LUK\": [\"나이트워커\", \"섀도어\", \"나이트로드\", \"듀얼블레이더\", \"팬텀\", \"호영\", \"칼리\", \"카데나\"],\n",
        "    \"HP\": [\"데몬어벤져\"],\n",
        "    \"STR_DEX_LUK\": [\"제논\"]\n",
        "}\n",
        "\n",
        "def get_main_stat(subclass):\n",
        "    for stat, jobs in main_stat_map.items():\n",
        "        if subclass in jobs:\n",
        "            return stat\n",
        "    return \"기타\"\n",
        "\n",
        "# 장비 정보 자동 채움\n",
        "def fill_missing_slots(user_input, subclass_profiles, top_slots):\n",
        "    subclass = user_input['subclass']\n",
        "    main_stat = get_main_stat(subclass)\n",
        "    filled = {}\n",
        "\n",
        "    for slot in top_slots:\n",
        "        if slot in user_input:\n",
        "            filled[slot] = user_input[slot]\n",
        "        else:\n",
        "            filled[slot] = subclass_profiles.get(subclass, {}).get(slot, {}).copy()\n",
        "\n",
        "        if 'main_stat_type' not in filled[slot] or filled[slot]['main_stat_type'] is None:\n",
        "            filled[slot]['main_stat_type'] = main_stat\n",
        "\n",
        "    return filled\n",
        "\n",
        "# 인코딩 + 스케일링 + 텐서 변환\n",
        "def encode_and_scale(filled_slots, subclass, encoders, scaler, cat_cols, num_cols):\n",
        "    x_cat_rows, x_cont_rows = [], []\n",
        "\n",
        "    for slot in filled_slots:\n",
        "        row_cat, row_cont = [], []\n",
        "\n",
        "        for col in cat_cols:\n",
        "            if col == 'subclass':\n",
        "                val = subclass\n",
        "            elif col == 'equipment_slot':\n",
        "                val = slot\n",
        "            else:\n",
        "                val = filled_slots[slot].get(col, subclass_profiles.get(subclass, {}).get(slot, {}).get(col, None))\n",
        "\n",
        "            if val is None:\n",
        "                val = encoders[col].classes_[0]\n",
        "            if isinstance(val, list):\n",
        "                val = '+'.join(val)\n",
        "            if val not in encoders[col].classes_:\n",
        "                val = encoders[col].classes_[0]\n",
        "\n",
        "            row_cat.append(encoders[col].transform([val])[0])\n",
        "\n",
        "        for col in num_cols:\n",
        "            val = filled_slots[slot].get(col, subclass_profiles.get(subclass, {}).get(slot, {}).get(col, 0.0))\n",
        "            row_cont.append(val)\n",
        "\n",
        "        x_cat_rows.append(row_cat)\n",
        "        x_cont_rows.append(row_cont)\n",
        "\n",
        "    x_cat_tensor = torch.tensor(x_cat_rows, dtype=torch.long).unsqueeze(0)\n",
        "    x_cont_tensor = torch.tensor(scaler.transform(x_cont_rows), dtype=torch.float32).unsqueeze(0)\n",
        "    mask_tensor = torch.tensor([[1] * len(filled_slots)], dtype=torch.float32)\n",
        "\n",
        "    equip_counts = mask_tensor.sum(dim=1, keepdim=True).repeat(1, x_cont_tensor.shape[1], 1)\n",
        "    x_cont_tensor = torch.cat([x_cont_tensor, equip_counts], dim=2)\n",
        "\n",
        "    return x_cat_tensor, x_cont_tensor, mask_tensor\n",
        "\n",
        "# phi(x) 벡터 추출\n",
        "def extract_user_vector(model, x_cat, x_cont, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        emb_cat = model._embed(x_cat.to(device))\n",
        "        x = torch.cat([emb_cat, x_cont.to(device)], dim=-1)\n",
        "        encoded = model.phi(x)\n",
        "        masked = encoded * mask.to(device).unsqueeze(-1)\n",
        "        pooled = masked.sum(dim=1)\n",
        "    return pooled.cpu().numpy()[0]\n",
        "\n",
        "# 유사도 계산 (subclass 동일한 유저만 대상)\n",
        "def recommend_similar_users(user_vec, hl_vecs, hl_nicks, df_stat_trimmed, target_subclass, top_k=5):\n",
        "    # subclass 기준 필터링\n",
        "    nick_to_idx = {nick: i for i, nick in enumerate(hl_nicks)}\n",
        "    filtered_nicks = df_stat_trimmed[df_stat_trimmed['subclass'] == target_subclass]['nickname'].tolist()\n",
        "    valid_indices = [nick_to_idx[nick] for nick in filtered_nicks if nick in nick_to_idx]\n",
        "\n",
        "    hl_vecs_filtered = hl_vecs[valid_indices]\n",
        "    hl_nicks_filtered = [hl_nicks[i] for i in valid_indices]\n",
        "\n",
        "    # 유사도 계산\n",
        "    sims = cosine_similarity(user_vec.reshape(1, -1), hl_vecs_filtered).flatten()\n",
        "    top_idx = sims.argsort()[-top_k:][::-1]\n",
        "    return [(hl_nicks_filtered[i], sims[i]) for i in top_idx]\n",
        "\n",
        "# 🔧 전체 실행 예시 흐름\n",
        "user_input = {\n",
        "    'subclass': '카인',\n",
        "    '무기': {\n",
        "        'item_group': '도전자',       # 장비 세트\n",
        "        'starforce': 15,              # 스타포스 강화 수치\n",
        "        'mainstat_total': 124,        # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 80,            # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 12,         # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '유니크',            # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': 'B',               # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'B',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': '기타', # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': '기타'  # 에디셔널 잠재옵션 3의 분류\n",
        "},\n",
        "    '모자': {\n",
        "        'item_group': '파프니르',       # 장비 세트\n",
        "        'starforce': 20,                # 스타포스 강화 수치\n",
        "        'mainstat_total': 300,          # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 78,              # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 6,            # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '레전드리',          # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': 'S',               # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'B',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': '기타', # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': 'B'     # 에디셔널 잠재옵션 3의 분류\n",
        "},\n",
        "    '장갑': {\n",
        "        'item_group': '앱솔랩스',       # 장비 세트\n",
        "        'starforce': 18,                # 스타포스 강화 수치\n",
        "        'mainstat_total': 100,          # 장비에 붙은 최종 주스탯\n",
        "        'power_total': 70,              # 장비에 붙은 최종 공격력/마력\n",
        "        'all_stat_total': 0,            # 장비에 붙은 최종 올스탯\n",
        "        'potential_option_grade': '유니크',            # 잠재옵션 등급\n",
        "        'additional_potential_option_grade': '에픽',   # 에디셔널 잠재옵션 등급\n",
        "        'potential_option_1_grade': 'S',               # 잠재옵션 1의 분류\n",
        "        'potential_option_2_grade': 'S',               # 잠재옵션 2의 분류\n",
        "        'potential_option_3_grade': '기타',            # 잠재옵션 3의 분류\n",
        "        'additional_potential_option_1_grade': 'S',    # 에디셔널 잠재옵션 1의 분류\n",
        "        'additional_potential_option_2_grade': 'S',    # 에디셔널 잠재옵션 2의 분류\n",
        "        'additional_potential_option_3_grade': '기타'  # 에디셔널 잠재옵션 3의 분류\n",
        "}\n",
        "}\n",
        "\n",
        "top_slots = ['무기', '모자', '장갑']\n",
        "\n",
        "filled = fill_missing_slots(user_input, subclass_profiles, top_slots)\n",
        "x_cat_new, x_cont_new, mask_new = encode_and_scale(\n",
        "    filled_slots=filled,\n",
        "    subclass=user_input['subclass'],\n",
        "    encoders=encoders,\n",
        "    scaler=scaler,\n",
        "    cat_cols=cat_cols,\n",
        "    num_cols=num_cols\n",
        ")\n",
        "\n",
        "user_vec = extract_user_vector(model, x_cat_new, x_cont_new, mask_new)\n",
        "\n",
        "# df_stat_trimmed = df_stat[['nickname', 'subclass']].drop_duplicates() 가정됨\n",
        "recommendations = recommend_similar_users(\n",
        "    user_vec=user_vec,\n",
        "    hl_vecs=hl_vecs,\n",
        "    hl_nicks=hl_nicks,\n",
        "    df_stat_trimmed=df_stat_trimmed,\n",
        "    target_subclass=user_input['subclass']\n",
        ")\n",
        "\n",
        "print(f\"\\n📌 직업: {user_input['subclass']}  |  주스탯: {get_main_stat(user_input['subclass'])}\")\n",
        "print(\"✨ 유사한 고레벨 유저 추천 ✨\\n\")\n",
        "for i, (nick, sim) in enumerate(recommendations, 1):\n",
        "    print(f\"{i}. 닉네임: {nick}  |  유사도: {sim:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arOTR4KDlNu-",
        "outputId": "e5a5d833-5c42-4678-f3ff-28aa7133896b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 직업: 카인  |  주스탯: DEX\n",
            "✨ 유사한 고레벨 유저 추천 ✨\n",
            "\n",
            "1. 닉네임: 샌핑  |  유사도: 0.9997\n",
            "2. 닉네임: 김만떽  |  유사도: 0.9997\n",
            "3. 닉네임: 꾸운감자  |  유사도: 0.9997\n",
            "4. 닉네임: 카링까지  |  유사도: 0.9997\n",
            "5. 닉네임: 동양의인재  |  유사도: 0.9997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-3 중요 장비 기반 전투력 예측 성능 테스트 (무기, 모자, 장갑)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 설정\n",
        "top_3_slots = ['무기', '모자', '장갑']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv', na_values=[], keep_default_na=False)\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# 전처리\n",
        "cat_cols = [\n",
        "    'subclass', 'equipment_slot', 'main_stat_type', 'item_group',\n",
        "    'starforce_scroll_flag', 'potential_option_grade', 'additional_potential_option_grade',\n",
        "    'main_pot_grade_summary', 'add_pot_grade_summary', 'potential_status'\n",
        "]\n",
        "num_cols = [\n",
        "    'boss_damage_total', 'ignore_monster_armor_total', 'all_stat_total', 'damage_total',\n",
        "    'boss_damage_add', 'damage_add', 'all_stat_add', 'starforce', 'special_ring_level',\n",
        "    'bonus_stat_total', 'mainstat_total', 'power_total', 'mainstat_add', 'power_add',\n",
        "    'mainstat_etc', 'power_etc', 'mainstat_starforce', 'power_starforce'\n",
        "]\n",
        "\n",
        "# Top-3 장비만 필터링\n",
        "df = df[df['equipment_slot'].isin(top_3_slots)].copy()\n",
        "df = df.dropna(subset=cat_cols + num_cols + ['전투력'])\n",
        "\n",
        "# 인코딩 및 스케일링\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])\n",
        "\n",
        "# 시퀀스 구성\n",
        "max_len = len(top_3_slots)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "# equip count 추가\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    model = DeepMaskedModel(embedding_info, x_cont.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    train_set = torch.utils.data.TensorDataset(x_cat[train_idx], x_cont[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = torch.utils.data.TensorDataset(x_cat[val_idx], x_cont[val_idx], mask[val_idx], y[val_idx])\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=256)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for xc, xc2, m, yt in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xc, xc2, m)\n",
        "            loss = criterion(pred, yt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xc, xc2, m, yt in val_loader:\n",
        "            pred = model(xc, xc2, m)\n",
        "            preds.append(pred.numpy())\n",
        "            targets.append(yt.numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    r2 = r2_score(targets, preds)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "    print(f\"Fold {fold+1}: RMSE={rmse:.4f}, R2={r2:.4f}\")\n",
        "\n",
        "print(f\"\\n📊 최종 평균 성능 (무기+모자+장갑): RMSE={np.mean(rmses):.4f}, R2={np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFT8GBF8uVL9",
        "outputId": "b985398d-0b4c-4e4e-ea38-0e39674a02bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: RMSE=0.5819, R2=0.5351\n",
            "Fold 2: RMSE=0.6507, R2=0.5182\n",
            "Fold 3: RMSE=0.5945, R2=0.6485\n",
            "Fold 4: RMSE=0.6057, R2=0.5964\n",
            "Fold 5: RMSE=0.5636, R2=0.7043\n",
            "\n",
            "📊 최종 평균 성능 (무기+모자+장갑): RMSE=0.5993, R2=0.6005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-10 중요 장비 기반 전투력 예측 성능 테스트 (무기, 모자, 하의, 신발, 장갑, 망토, 어깨장식)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# 설정\n",
        "selected_slots = ['무기', '모자', '하의', '신발', '장갑', '망토', '어깨장식']\n",
        "selected_features = ['item_group', 'starforce', 'mainstat_total', 'power_total',\n",
        "                     'potential_option_grade', 'additional_potential_option_grade']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/item_nomissingvalues_copy.csv')\n",
        "df_stat = pd.read_csv('/content/drive/MyDrive/data/merged/stat_merged.csv')\n",
        "df_stat_trimmed = df_stat[['nickname', 'subclass', '전투력']].drop_duplicates()\n",
        "df = df.merge(df_stat_trimmed, on=['nickname', 'subclass'], how='left')\n",
        "df.dropna(subset=['전투력'], inplace=True)\n",
        "\n",
        "# 필터링 및 전처리\n",
        "df = df[df['equipment_slot'].isin(selected_slots)].copy()\n",
        "df = df.dropna(subset=selected_features + ['전투력'])\n",
        "\n",
        "# 피처 분리\n",
        "cat_cols = ['item_group', 'potential_option_grade', 'additional_potential_option_grade']\n",
        "num_cols = ['starforce', 'mainstat_total', 'power_total']\n",
        "\n",
        "# 인코딩 + 스케일링\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in cat_cols}\n",
        "for col in cat_cols:\n",
        "    df[col] = encoders[col].transform(df[col])\n",
        "scaler = StandardScaler()\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "df['log_전투력'] = np.log1p(df['전투력'])\n",
        "\n",
        "# 시퀀스 구성\n",
        "max_len = len(selected_slots)\n",
        "df = df.sort_values(\"nickname\")\n",
        "\n",
        "x_cat_list, x_cont_list, mask_list, y_list = [], [], [], []\n",
        "\n",
        "for name, group in df.groupby(\"nickname\"):\n",
        "    cat = group[cat_cols].values.astype(np.int64)\n",
        "    cont = group[num_cols].values.astype(np.float32)\n",
        "    valid_len = len(group)\n",
        "\n",
        "    if valid_len < max_len:\n",
        "        pad_cat = np.zeros((max_len - valid_len, len(cat_cols)))\n",
        "        pad_cont = np.zeros((max_len - valid_len, len(num_cols)))\n",
        "        pad_mask = [0] * (max_len - valid_len)\n",
        "        cat = np.vstack([cat, pad_cat])\n",
        "        cont = np.vstack([cont, pad_cont])\n",
        "        mask = [1] * valid_len + pad_mask\n",
        "    else:\n",
        "        cat = cat[:max_len]\n",
        "        cont = cont[:max_len]\n",
        "        mask = [1] * max_len\n",
        "\n",
        "    x_cat_list.append(torch.tensor(cat, dtype=torch.long))\n",
        "    x_cont_list.append(torch.tensor(cont, dtype=torch.float32))\n",
        "    mask_list.append(torch.tensor(mask, dtype=torch.float32))\n",
        "    y_list.append(np.log1p(group['전투력'].iloc[0]))\n",
        "\n",
        "x_cat = torch.stack(x_cat_list)\n",
        "x_cont = torch.stack(x_cont_list)\n",
        "mask = torch.stack(mask_list)\n",
        "y = torch.tensor(y_list, dtype=torch.float32)\n",
        "\n",
        "# 장비 개수 feature 추가\n",
        "equip_counts = mask.sum(dim=1).unsqueeze(1).repeat(1, x_cont.shape[1]).unsqueeze(2)\n",
        "x_cont = torch.cat([x_cont, equip_counts], dim=2)\n",
        "\n",
        "embedding_info = {col: df[col].nunique() for col in cat_cols}\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "rmses, r2s = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(x_cat)):\n",
        "    model = DeepMaskedModel(embedding_info, x_cont.shape[-1])\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    train_set = torch.utils.data.TensorDataset(x_cat[train_idx], x_cont[train_idx], mask[train_idx], y[train_idx])\n",
        "    val_set = torch.utils.data.TensorDataset(x_cat[val_idx], x_cont[val_idx], mask[val_idx], y[val_idx])\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=256)\n",
        "\n",
        "    for epoch in range(5):\n",
        "        model.train()\n",
        "        for xc, xc2, m, yt in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(xc, xc2, m)\n",
        "            loss = criterion(pred, yt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for xc, xc2, m, yt in val_loader:\n",
        "            pred = model(xc, xc2, m)\n",
        "            preds.append(pred.numpy())\n",
        "            targets.append(yt.numpy())\n",
        "\n",
        "    preds = np.concatenate(preds)\n",
        "    targets = np.concatenate(targets)\n",
        "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
        "    r2 = r2_score(targets, preds)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "    print(f\"Fold {fold+1}: RMSE={rmse:.4f}, R2={r2:.4f}\")\n",
        "\n",
        "print(f\"\\n📊 최종 평균 성능 (7개 장비 핵심 피처): RMSE={np.mean(rmses):.4f}, R2={np.mean(r2s):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS5wqli7wape",
        "outputId": "a4ddcc4c-d4eb-45d6-c795-a17de55bff56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-b03c4d71cc1a>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoders[col].transform(df[col])\n",
            "<ipython-input-101-b03c4d71cc1a>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col] = encoders[col].transform(df[col])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: RMSE=0.7845, R2=0.4024\n",
            "Fold 2: RMSE=0.6897, R2=0.5501\n",
            "Fold 3: RMSE=0.6644, R2=0.5335\n",
            "Fold 4: RMSE=0.6826, R2=0.4811\n",
            "Fold 5: RMSE=0.6304, R2=0.5600\n",
            "\n",
            "📊 최종 평균 성능 (7개 장비 핵심 피처): RMSE=0.6903, R2=0.5054\n"
          ]
        }
      ]
    }
  ]
}