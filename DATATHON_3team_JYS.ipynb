{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. APIÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞"
      ],
      "metadata": {
        "id": "ckUqbMZiUP2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yLjyPbHT_ce"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# API Key Î∞è Ìó§Îçî ÏÑ§Ï†ï\n",
        "API_KEY = \"api ÌÇ§Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî\"\n",
        "headers = {\"x-nxopen-api-key\": API_KEY}\n",
        "session = requests.Session()\n",
        "session.headers.update(headers)\n",
        "\n",
        "# ÎÇ†Ïßú ÏÑ§Ï†ï\n",
        "target_date = \"ÎÇ†ÏßúÎ•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî\"\n",
        "\n",
        "# STEP 1: Ï¢ÖÌï© Îû≠ÌÇπ Î≥ëÎ†¨ Ï°∞Ìöå\n",
        "print(\"\\u25b6 STEP 1: Ï¢ÖÌï© Îû≠ÌÇπ Ï°∞Ìöå (Î≥ëÎ†¨)\")\n",
        "\n",
        "def fetch_ranking_page(page):\n",
        "    url = f\"https://open.api.nexon.com/maplestory/v1/ranking/overall?date={target_date}&page={page}\"\n",
        "    try:\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            return [\n",
        "                {\"character_name\": u[\"character_name\"], \"world_name\": u[\"world_name\"],\"ranking\": u.get(\"ranking\")}\n",
        "                for u in res.json().get(\"ranking\", [])\n",
        "            ]\n",
        "        else:\n",
        "            print(f\"‚ùå Page {page} Îã®Ïùº: {res.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Page {page} ÏòàÏô∏: {e}\")\n",
        "    return []\n",
        "\n",
        "user_list = []\n",
        "with ThreadPoolExecutor(max_workers=50) as executor:\n",
        "    futures = [executor.submit(fetch_ranking_page, page) for page in range(1, 3001)]  # 600,000Î™ÖÍπåÏßÄÎßå Ï°∞Ìöå\n",
        "    for i, future in enumerate(as_completed(futures), 1):\n",
        "        user_list.extend(future.result())\n",
        "        if i % 100 == 0:\n",
        "            print(f\"üîπ STEP 1 ÏßÑÌñâÎ•†: {i} ÌéòÏù¥ÏßÄ ÏôÑÎ£å\")\n",
        "\n",
        "print(f\"Ï¥ù {len(user_list)}Î™ÖÏùò ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ ÌöçÎìù.\")\n",
        "\n",
        "# Îπ†Î•¥Í≤å ÌÖåÏä§Ìä∏ÌïòÍ∏∞ ÏúÑÌï¥ ÏÉÅÏúÑ 100Î™ÖÎßå ÏÑ†ÌÉù\n",
        "#user_list = user_list[:100]\n",
        "\n",
        "# STEP 2: ocid Ï°∞Ìöå\n",
        "print(\"\\u25b6 STEP 2: ocid Ï°∞Ìöå (ÎèôÏãú Ï≤òÎ¶¨)\")\n",
        "\n",
        "def fetch_ocid(user):\n",
        "    name = user[\"character_name\"]\n",
        "    world = user[\"world_name\"]\n",
        "    url = f\"https://open.api.nexon.com/maplestory/v1/id?character_name={name}&world_name={world}\"\n",
        "    try:\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            user[\"ocid\"] = res.json().get(\"ocid\")\n",
        "        else:\n",
        "            user[\"ocid\"] = None\n",
        "            print(f\"‚ùå ocid Ïò§Î•ò: {name} ({world}) - ÏÉÅÌÉú ÏΩîÎìú {res.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ocid ÏòàÏô∏: {name} ({world}) - {e}\")\n",
        "        user[\"ocid\"] = None\n",
        "    return user\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=50) as executor:\n",
        "    futures = [executor.submit(fetch_ocid, user) for user in user_list]\n",
        "    for future in as_completed(futures):\n",
        "        _ = future.result()\n",
        "\n",
        "print(\"ocid Ï°∞Ìöå ÏôÑÎ£å.\")\n",
        "\n",
        "# STEP 3: ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Ï°∞Ìöå\n",
        "print(\"\\u25b6 STEP 3: ÏÑ∏Î∂Ä Ï†ïÎ≥¥ Ï°∞Ìöå (ÎèôÏãú Ï≤òÎ¶¨)\")\n",
        "\n",
        "def fetch_details(user):\n",
        "    ocid = user.get(\"ocid\")\n",
        "    if not ocid:\n",
        "        return None\n",
        "\n",
        "    result = {\n",
        "        \"ocid\": ocid,                        # Ï∂îÍ∞Ä\n",
        "        \"ranking\": user.get(\"ranking\"),     # Ï∂îÍ∞Ä\n",
        "        \"character_name\": user[\"character_name\"],\n",
        "        \"world_name\": user[\"world_name\"],\n",
        "        \"character_gender\": None,\n",
        "        \"character_class\": None,\n",
        "        \"character_class_level\": None,\n",
        "        \"character_level\": None,\n",
        "        \"character_exp\": None,\n",
        "        \"character_exp_rate\": None,\n",
        "        \"character_guild_name\": None,\n",
        "        \"character_date_create\": None,\n",
        "        \"access_flag\": \"false\",\n",
        "        \"liberation_quest_clear_flag\": \"false\",\n",
        "        \"popularity\": None,\n",
        "        \"arcane_sum\": None,\n",
        "        \"authentic_sum\": None,\n",
        "        \"set_absorlab_count\": 0,\n",
        "        \"set_lubatiss_count\": 0,\n",
        "        \"set_arcane_count\": 0,\n",
        "        \"set_eternal_count\": 0,\n",
        "        \"dojang_best_floor\": None,\n",
        "        \"union_level\": None,\n",
        "        \"union_artifact_level\": None,\n",
        "        \"union_artifact_exp\": None,\n",
        "        \"union_artifact_point\": None\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/character/basic?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            j = res.json()\n",
        "            result[\"character_gender\"] = j.get(\"character_gender\")\n",
        "            result[\"character_class\"] = j.get(\"character_class\")\n",
        "            result[\"character_class_level\"] = j.get(\"character_class_level\")\n",
        "            result[\"character_level\"] = j.get(\"character_level\")\n",
        "            result[\"character_exp\"] = j.get(\"character_exp\")\n",
        "            result[\"character_exp_rate\"] = j.get(\"character_exp_rate\")\n",
        "            result[\"character_guild_name\"] = j.get(\"character_guild_name\")\n",
        "            result[\"character_date_create\"] = j.get(\"character_date_create\")\n",
        "            result[\"access_flag\"] = j.get(\"access_flag\", \"false\")\n",
        "            result[\"liberation_quest_clear_flag\"] = j.get(\"liberation_quest_clear_flag\", \"false\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Í∏∞Î≥∏ Ï†ïÎ≥¥ Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/character/popularity?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            result[\"popularity\"] = res.json().get(\"popularity\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ïù∏Í∏∞ÎèÑ Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/character/symbol-equipment?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            symbols = res.json().get(\"symbol\", [])\n",
        "            result[\"arcane_sum\"] = sum(s.get(\"symbol_level\", 0) for s in symbols if \"ÏïÑÏºÄÏù∏\" in s.get(\"symbol_name\", \"\"))\n",
        "            result[\"authentic_sum\"] = sum(s.get(\"symbol_level\", 0) for s in symbols if \"Ïñ¥ÏÑºÌã±\" in s.get(\"symbol_name\", \"\"))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ïã¨Î≥º Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/character/set-effect?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            sets = res.json().get(\"set_effect\", [])\n",
        "            for s in sets:\n",
        "                name = s.get(\"set_name\", \"\")\n",
        "                count = s.get(\"total_set_count\", 0)\n",
        "                if \"Ïï±ÏÜîÎû©Ïä§\" in name:\n",
        "                    result[\"set_absorlab_count\"] += count\n",
        "                elif \"Î£®ÌÉÄÎπÑÏä§\" in name:\n",
        "                    result[\"set_lubatiss_count\"] += count\n",
        "                elif \"ÏïÑÏºÄÏù∏ÏÖ∞Ïù¥Îìú\" in name:\n",
        "                    result[\"set_arcane_count\"] += count\n",
        "                elif \"ÏóêÌÖåÎ•¥ÎÑ¨\" in name:\n",
        "                    result[\"set_eternal_count\"] += count\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ÏÑ∏Ìä∏ Ìö®Í≥º Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/character/dojang?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            result[\"dojang_best_floor\"] = res.json().get(\"dojang_best_floor\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ÎèÑÏû• Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    try:\n",
        "        url = f\"https://open.api.nexon.com/maplestory/v1/user/union?ocid={ocid}&date={target_date}\"\n",
        "        res = session.get(url, timeout=10)\n",
        "        if res.status_code == 200:\n",
        "            j = res.json()\n",
        "            result[\"union_level\"] = j.get(\"union_level\")\n",
        "            result[\"union_artifact_level\"] = j.get(\"union_artifact_level\")\n",
        "            result[\"union_artifact_exp\"] = j.get(\"union_artifact_exp\")\n",
        "            result[\"union_artifact_point\"] = j.get(\"union_artifact_point\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Ïú†ÎãàÏò® Ïã§Ìå® ({ocid}): {e}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "# STEP 3 Ïã§Ìñâ\n",
        "detailed_info = []\n",
        "with ThreadPoolExecutor(max_workers=50) as executor:\n",
        "    futures = [executor.submit(fetch_details, user) for user in user_list if user.get(\"ocid\")]\n",
        "    for future in as_completed(futures):\n",
        "        res = future.result()\n",
        "        if res is not None:\n",
        "            detailed_info.append(res)\n",
        "\n",
        "# STEP 4: CSV Ï†ÄÏû•\n",
        "print(\"\\u25b6 STEP 4: CSV Ï†ÄÏû•\")\n",
        "df_out = pd.DataFrame(detailed_info)\n",
        "output_filename = f\"achievement_fullinfo_{target_date}.csv\"\n",
        "df_out.to_csv(output_filename, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"‚úÖ ÏôÑÎ£å! Ï†ÄÏû•Îêú ÌååÏùº: {output_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ"
      ],
      "metadata": {
        "id": "_W546S4uVLSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ÌååÏùº Î°úÎìú\n",
        "# Ïã§Ï†ú ÌååÏùº Í≤ΩÎ°úÎ°ú Î≥ÄÍ≤ΩÌï¥ Ï£ºÏÑ∏Ïöî\n",
        "file_oct17 = '/content/drive/MyDrive/·Ñâ·Ö¢·Ñë·Ö©·ÜØ·ÑÉ·Ö•/·Ñè·Ö¢·ÑÖ·Öµ·Ü®·Ñê·Ö• ·ÑÖ·Ö¶·Ñá·Ö¶·ÜØ ·ÑÄ·Öµ·Ñå·ÖÆ·Ü´/·ÑÇ·Ö°·ÜØ·Ñç·Ö°·Ñá·Öß·ÜØ ·ÑÜ·Ö©·Ñã·Ö≥·Ü∑/character_level_2024-10-17.csv'  # 10Ïõî 17Ïùº ÌååÏùº Í≤ΩÎ°ú\n",
        "file_oct10 = '/content/drive/MyDrive/achievement_fullinfo_2024-10-10.csv'  # 10Ïõî 10Ïùº ÌååÏùº Í≤ΩÎ°ú\n",
        "\n",
        "# ÌååÏùº ÏùΩÍ∏∞\n",
        "df_oct17 = pd.read_csv(file_oct17)\n",
        "df_oct10 = pd.read_csv(file_oct10)\n",
        "\n",
        "# 10Ïõî 17Ïùº ÌååÏùºÏóêÏÑú character_levelÏù¥ 270 Ïù¥ÏÉÅÏù∏ ocid Ï∂îÏ∂ú\n",
        "high_level_ocids = df_oct17[df_oct17['character_level'] >= 270]['ocid'].unique()\n",
        "\n",
        "print(f\"10Ïõî 17Ïùº ÌååÏùºÏóêÏÑú character_levelÏù¥ 270 Ïù¥ÏÉÅÏù∏ ocid Ïàò: {len(high_level_ocids)}\")\n",
        "\n",
        "# 10Ïõî 10Ïùº ÌååÏùºÏóêÏÑú Ïù¥ ocidÎì§Îßå ÌïÑÌÑ∞ÎßÅ\n",
        "filtered_oct10 = df_oct10[df_oct10['ocid'].isin(high_level_ocids)]\n",
        "\n",
        "print(f\"10Ïõî 10Ïùº ÌååÏùºÏóêÏÑú Îß§Ïπ≠Îêú ocid Ïàò: {len(filtered_oct10['ocid'].unique())}\")\n",
        "\n",
        "# Í≤∞Í≥º Ï†ÄÏû•\n",
        "filtered_oct10.to_csv('filtered_oct10_result.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(\"ÌïÑÌÑ∞ÎßÅ ÏôÑÎ£å! Í≤∞Í≥ºÍ∞Ä 'filtered_oct10_result.csv'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
      ],
      "metadata": {
        "id": "Zxlp5OIOUV0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) ÏõêÎ≥∏ CSV Î∂àÎü¨Ïò§Í∏∞ ‚îÄ ÌååÏùº Í≤ΩÎ°úÎ•º ÎßûÍ≤å ÏàòÏ†ï\n",
        "file_path = \"/content/drive/MyDrive/·Ñâ·Ö¢·Ñë·Ö©·ÜØ·ÑÉ·Ö•/·Ñè·Ö¢·ÑÖ·Öµ·Ü®·Ñê·Ö• ·ÑÖ·Ö¶·Ñá·Ö¶·ÜØ ·ÑÄ·Öµ·Ñå·ÖÆ·Ü´/·Ñá·Öß·Üº·Ñí·Ö°·Ü∏·Ñí·Ö°·ÑÄ·Öµ ·Ñã·Ö±·Ñí·Ö°·Ü´ ·ÑÄ·Ö™·Ñå·Ö•·Üº/final_data_changed_only.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 2) exp_1010Ïù¥ NaNÏù∏ Ìñâ Ï†úÍ±∞\n",
        "df_clean = df.dropna(subset=[\"exp_1010\"]).reset_index(drop=True)\n",
        "\n",
        "# 3) ÏÉà CSVÎ°ú Ï†ÄÏû• ‚îÄ ÎçÆÏñ¥Ïì∞Í±∞ÎÇò, Îã§Î•∏ Ïù¥Î¶ÑÏúºÎ°ú Î∂ÑÎ¶¨ Ï†ÄÏû•\n",
        "save_path = \"/content/final_clean_1010~1017.csv\"\n",
        "df_clean.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"‚úÖ Í≤∞Ï∏° Ìñâ Ï†úÍ±∞ Î∞è Ï†ÄÏû• ÏôÑÎ£å ‚Üí {save_path}  (ÎÇ®ÏùÄ Ìñâ Ïàò: {len(df_clean)})\")\n"
      ],
      "metadata": {
        "id": "akAy2cbmVksy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. LSTM"
      ],
      "metadata": {
        "id": "JE0QU54sWm5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lifelines\n",
        "from lifelines.utils import concordance_index"
      ],
      "metadata": {
        "id": "c6M-zPjzWuVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Ew8PZsMuWmqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/time_series_final1.csv\", parse_dates=[\"snapshot_date\"])"
      ],
      "metadata": {
        "id": "5y3ajeExW3i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎÇ†Ïßú Ï≤òÎ¶¨\n",
        "df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_date\"], errors=\"coerce\")\n",
        "df[\"character_date_create\"] = pd.to_datetime(df[\"character_date_create\"], errors=\"coerce\")\n",
        "df = df[df[\"character_class_level\"] == 6].copy()\n",
        "df = df.sort_values(by=[\"ocid\", \"snapshot_date\"])\n",
        "\n",
        "# ÌååÏÉù ÌîºÏ≤ò ÏÉùÏÑ±\n",
        "df[\"has_guild\"] = df[\"character_guild_name\"].notna().astype(int)\n",
        "df['snapshot_date'] = df['snapshot_date'].dt.tz_localize(None)\n",
        "df['character_date_create'] = df['character_date_create'].dt.tz_localize(None)\n",
        "df['account_age_days'] = (df['snapshot_date'] - df['character_date_create']).dt.days.clip(lower=0)\n",
        "\n",
        "# ÏÑ†ÌÉù ÌîºÏ≤ò\n",
        "selected_features = [\n",
        "    \"world_name\", \"character_class\", \"liberation_quest_clear_flag\",\n",
        "    \"popularity\", \"arcane_sum\", \"authentic_sum\", \"union_level\", \"authentic_growth_sum\",\n",
        "    \"has_guild\", \"account_age_days\"\n",
        "]\n",
        "\n",
        "# ocid Í∏∞Ï§Ä train/test Î∂ÑÎ¶¨\n",
        "unique_ocids = df['ocid'].unique()\n",
        "train_ocids, test_ocids = train_test_split(unique_ocids, test_size=0.2, random_state=42)\n",
        "train_df_all = df[df['ocid'].isin(train_ocids)].copy()\n",
        "test_df = df[df['ocid'].isin(test_ocids)].copy()\n",
        "\n",
        "# ocid Í∏∞Ï§ÄÏúºÎ°ú train/val Î∂ÑÎ¶¨ (Í≤ÄÏ¶ùÏÖã ÎàÑÏàò Î∞©ÏßÄÏö©)\n",
        "train_ocids_sub, val_ocids = train_test_split(train_ocids, test_size=0.2, random_state=42)\n",
        "train_df = train_df_all[train_df_all['ocid'].isin(train_ocids_sub)].copy()\n",
        "val_df = train_df_all[train_df_all['ocid'].isin(val_ocids)].copy()\n",
        "\n",
        "# Î≤îÏ£ºÌòï Ïù∏ÏΩîÎî© - ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ\n",
        "cat_cols = [\"world_name\", \"character_class\"]\n",
        "encoded_features = []\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train_df[col].astype(str))\n",
        "\n",
        "    # Create new column names for encoded features\n",
        "    new_col_name = f\"{col}_encoded\"\n",
        "    encoded_features.append(new_col_name)\n",
        "\n",
        "    # Transform known values and handle unknown values\n",
        "    for sub_df in [train_df, val_df, test_df]:\n",
        "        sub_df[new_col_name] = -1  # Default for unknown values\n",
        "        # Only transform values that exist in the training set\n",
        "        mask = sub_df[col].astype(str).isin(le.classes_)\n",
        "        sub_df.loc[mask, new_col_name] = le.transform(sub_df.loc[mask, col].astype(str))\n",
        "        # Replace -1 (unknown values) with 0 (first class)\n",
        "        sub_df[new_col_name] = sub_df[new_col_name].replace(-1, 0)\n",
        "\n",
        "# Î∂àÎ¶¨Ïñ∏\n",
        "for sub_df in [train_df, val_df, test_df]:\n",
        "    sub_df[\"liberation_quest_clear_flag\"] = sub_df[\"liberation_quest_clear_flag\"].astype(int)\n",
        "\n",
        "# ÏàòÏ†ïÎêú ÌäπÏÑ± Î¶¨Ïä§Ìä∏ (Ïπ¥ÌÖåÍ≥†Î¶¨Ïª¨ Î≥ÄÏàò ÍµêÏ≤¥)\n",
        "modified_features = [feat if feat not in cat_cols else f\"{feat}_encoded\" for feat in selected_features]\n",
        "\n",
        "# Ï†ïÍ∑úÌôî - Ïà´ÏûêÌòï ÌîºÏ≤òÎßå ÏÑ†ÌÉù\n",
        "numeric_features = [feat for feat in modified_features if feat not in [\"world_name_encoded\", \"character_class_encoded\"]]\n",
        "category_features = [\"world_name_encoded\", \"character_class_encoded\"]\n",
        "\n",
        "# Ïà´ÏûêÌòï ÌîºÏ≤òÎßå Ï†ïÍ∑úÌôî\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_df[numeric_features])\n",
        "for sub_df in [train_df, val_df, test_df]:\n",
        "    sub_df[numeric_features] = scaler.transform(sub_df[numeric_features])"
      ],
      "metadata": {
        "id": "QhbjC6KFVsrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÏãúÌÄÄÏä§ ÏÉùÏÑ± Ìï®Ïàò\n",
        "def create_sequences(df, seq_len=10):\n",
        "    X_list, y_list = [], []\n",
        "    for ocid, group in df.groupby(\"ocid\"):\n",
        "        group = group.sort_values(\"snapshot_date\")\n",
        "        features = group[modified_features].values\n",
        "        if len(features) >= 2:\n",
        "            last_event = group[\"event\"].iloc[-1]\n",
        "            for i in range(len(group) - seq_len + 1):\n",
        "                seq = features[i:i+seq_len]\n",
        "                if len(seq) == seq_len:\n",
        "                    X_list.append(seq)\n",
        "                    y_list.append(group[\"event\"].iloc[i+seq_len-1])\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "# ÏãúÌÄÄÏä§ ÏÉùÏÑ±\n",
        "SEQ_LEN = 10\n",
        "X_train, event_train = create_sequences(train_df, SEQ_LEN)\n",
        "X_val, event_val = create_sequences(val_df, SEQ_LEN)\n",
        "X_test, event_test = create_sequences(test_df, SEQ_LEN)\n",
        "\n",
        "# NaN Ï†úÍ±∞\n",
        "X_train = np.nan_to_num(X_train)\n",
        "X_val = np.nan_to_num(X_val)\n",
        "X_test = np.nan_to_num(X_test)\n",
        "event_train = np.nan_to_num(event_train).astype(int)\n",
        "event_val = np.nan_to_num(event_val).astype(int)\n",
        "event_test = np.nan_to_num(event_test).astype(int)\n",
        "\n",
        "# ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Î≥¥Ï†ï\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(event_train),\n",
        "    y=event_train\n",
        ")\n",
        "class_weights = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "# Î™®Îç∏ Ï†ïÏùò\n",
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Masking(mask_value=0.0, input_shape=input_shape),\n",
        "        LSTM(64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "        LSTM(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2),\n",
        "        Dropout(0.4),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "A-Ecczo8W_U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Î™®Îç∏ ÌïôÏäµ\n",
        "model = build_model((SEQ_LEN, len(modified_features)))\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
        "    ReduceLROnPlateau(patience=3, factor=0.5, min_lr=1e-5, monitor='val_loss')\n",
        "]\n",
        "history = model.fit(\n",
        "    X_train, event_train,\n",
        "    validation_data=(X_val, event_val),\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ÏòàÏ∏° Î∞è ÌèâÍ∞Ä\n",
        "pred_risk = model.predict(X_test).flatten()\n",
        "auc = roc_auc_score(event_test, pred_risk)\n",
        "print(f\"ROC-AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "Zmsy-KnfXBCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ÏµúÏ†Å threshold Ï†ÅÏö©\n",
        "final_preds = (pred_risk >= best_threshold).astype(int)\n",
        "\n",
        "# ÏÑ±Îä• ÌèâÍ∞Ä ÏßÄÌëú\n",
        "print(\"Classification Report (Optimal Threshold):\\n\")\n",
        "print(classification_report(event_test, final_preds, digits=4))\n",
        "\n",
        "# ÌòºÎèô ÌñâÎ†¨\n",
        "cm = confusion_matrix(event_test, final_preds)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Pred: 0\", \"Pred: 1\"], yticklabels=[\"True: 0\", \"True: 1\"])\n",
        "plt.title(f\"Confusion Matrix (Threshold = {best_threshold:.2f})\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HtY5IBGvXkmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "# ÏûÑÍ≥ÑÍ∞í Ï†ÅÏö© (Í∏∞Î≥∏ 0.5)\n",
        "threshold = 0.5\n",
        "pred_label = (pred_risk >= threshold).astype(int)\n",
        "\n",
        "# classification report Ï∂úÎ†•\n",
        "report = classification_report(event_test, pred_label, digits=4)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Confusion Matrix ÏãúÍ∞ÅÌôî\n",
        "conf_matrix = confusion_matrix(event_test, pred_label)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q5BX240HXurL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}